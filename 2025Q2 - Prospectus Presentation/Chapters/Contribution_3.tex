\section{Contribution 3}

% For each Contribution:
%     Introduction
%         Recall Motivation
%         Lit review
%         Contribution
%     Methodology
%     Experimental Procedure
%     Results
%     Discussion
\subsection{Introduction}

\subsubsection{Literature Review}

\subsubsection{Research Questions}

\begin{frame}{Contribution 3 - Research Questions}
    \begin{enumerate}
        \item[RQ 1] {
            To what (if any) extent do graph-based policies improve learning efficiency 
            in heterogeneous-agent environments compared to other architectures?
            }
        \item[RQ 2] {
            How robust are graph-based policies to perturbations such as changes to 
            partial observability and changes in team composition?
            }
        \item[RQ 3] {
            What are the computational and implementation costs of graph-based 
            architectures relative to their performance benefits?
            }
    \end{enumerate}
\end{frame}

\begin{frame}{RQ 1 - Research Tasks}
    \begin{enumerate}
        \item[RQ 1] \textcolor{gray}{ 
            To what (if any) extent do graph-based policies improve learning efficiency 
            in heterogeneous-agent environments compared to other architectures? } \vspace{1em}
    \begin{itemize}
        \item[RT 1.1] {
            Implement and train a graph-based architecture such as 
            PIC in the custom heterogeneous environment.}
        \item[RT 1.2] {
            Measure convergence rates and final performance across 
            multiple team compositions and sizes.}
        \item[RT 1.3] {
            Compare against performance of input-invariant and 
            non-shared baselines (from Contribution 2).}
    \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}{RQ 2 - Research Tasks}
    \begin{enumerate}
        \item[RQ 2] \textcolor{gray}{ 
            How robust are graph-based policies to perturbations such as changes to 
            partial observability and changes in team composition? } \vspace{1em}
    \begin{itemize}
        \item[RT 2.1] {
            Evaluate robustness to agent dropout and team-size changes at test time.}
        \item[RT 2.2] {
            Introduce random observation channel masking and measure recovery/stability.}
        \item[RT 2.3] {
            Compare perturbation response curves with Contribution 2 architectures.}
    \end{itemize}
    \end{enumerate}
\end{frame}

\begin{frame}{RQ 3 - Research Tasks}
    \begin{enumerate}
        \item[RQ 3] \textcolor{gray}{ 
            What are the computational and implementation costs of graph-based 
            architectures relative to their performance benefits? }
        \vspace{1em}
        \begin{itemize}
            \item[RT 3.1] {
                Benchmark computational cost during training and 
                inference (e.g., agent-steps, step-costs).}
            \item[RT 3.2] {
                Perform Statistical comparison of relative training cost, rate of convergence, 
                in training and rate of performance degradation in completed models.}
        \end{itemize}
    \end{enumerate}
\end{frame}







\subsubsection{Training Architectures}

\begin{frame}{Architectures Compared (RT 1.1,1.4)}
    \textbf{Models Evaluated}
    \begin{enumerate}
        \item \textbf{HAPPO (Baseline)}\footcite{zhong2024} As used in Contribution 2
        \item \textbf{Mean-Field } From Contribution 2
        \item \textbf{PIC}\footcite{liu2020b}
          \begin{itemize}
            % \item \emph{COMA + GNN + Transformer}
            \item \emph{GNN + MADDPG}
            \item Graph neural network for relational encoding.
            \item Transformer-based critic for contextual estimation.
            \item Chosen due to its conceptual similarity to the author's own attempted 
                implementation of a minimal GNN-based MARL architecture:
            \begin{itemize}
                \item Efforts to independently develop a simple graph-based model yielded architecture nearly equivalent to PIC.
                \item Provides a representative implementation for graph-based learning in MARL under heterogeneous conditions.
                \item Well-established architecture that integrates GNN message passing and attention mechanisms in a scalable way.
            \end{itemize}
          \end{itemize}
    \end{enumerate}
\end{frame}


% \subsection{Methodology}
% \subsection{Experimental Procedure}
% \subsection{Results}
% \subsection{Discussion}