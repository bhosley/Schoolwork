
% General AI
\newabbreviation{ai}{AI}{artificial intelligence}
\newabbreviation{asha}{ASHA}{asynchronous successive halving algorithm}
\newabbreviation{ctde}{CTDE}{centralized training with decentralized execution}
\newabbreviation{dnn}{DNN}{deep neural network}
\newabbreviation{dqn}{DQN}{Deep Q-Network}
\newabbreviation{gae}{GAE}{generalized advantage estimator}
\newabbreviation{gnn}{GNN}{graph neural network}
\newabbreviation{mlp}{MLP}{mulit-layer perceptron}

% RL Algorithms
\newabbreviation{rl}{RL}{reinforcement learning}
\newabbreviation{marl}{MARL}{multi-agent reinforcement learning}
\newabbreviation{harl}{HARL}{heterogeneous-agent reinforcement learning}

\newabbreviation{a2c}{A2C}{advantage actor-critic}
\newabbreviation{a3c}{A3C}{asynchronous advantage actor-critic}
\newabbreviation{haa2c}{HAA2C}{heterogeneous-agent \gls{a3c}}
\newabbreviation{impala}{IMPALA}{importance weighted actor-learner architecture}

\newabbreviation{ddpg}{DDPG}{deep-deterministic policy gradient}
\newabbreviation{maddpg}{MADDPG}{multi-agent deep-deterministic policy gradient}
\newabbreviation{haddpg}{HADDPG}{heterogeneous-agent deep-deterministic policy gradient}

\newabbreviation{td3}{TD3}{twin-delayed deep-deterministic policy gradient}
\newabbreviation{matd3}{MATD3}{multi-agent \gls{td3}}
\newabbreviation{hatd3}{HATD3}{heterogeneous-agent \gls{td3}}

\newabbreviation{ppo}{PPO}{proximal policy optimization}
\newabbreviation{ippo}{IPPO}{independent \gls{ppo}}
\newabbreviation{happo}{HAPPO}{heterogeneous-agent \gls{ppo}}
\newabbreviation{mappo}{MAPPO}{multi-agent \gls{ppo}}

\newabbreviation{trpo}{TRPO}{trust region policy optimization}
\newabbreviation{hatrpo}{HATRPO}{heterogeneous-agent \gls{trpo}}
\newabbreviation{matrpo}{MATRPO}{multi-agent \gls{trpo}}

\newabbreviation{coma}{COMA}{counterfactual multi-agent policy gradients}
\newabbreviation{hpn}{HPN}{hyper policy network}
\newabbreviation{pic}{PIC}{permutation-invariant critic}
\newabbreviation{pipo}{PIPO}{permutation invariant policy optimization}
\newabbreviation{reinforce}{REINFORCE}{
    REward Increment = Nonnegative Factor 
    x Offset Reinforcement x Characteristic Eligibility}
\newabbreviation{vdn}{VDN}{value decomposition networks}

% Environments
\newabbreviation{grf}{GRF}{Google research football}
\newabbreviation{lbf}{LBF}{Level-based Foraging}
\newabbreviation{mpe}{MPE}{Multi Particle Environments}
\newabbreviation{sisl}{SISL}{Stanford Intelligent Systems Laboratory}

% Stochastic and Games
\newabbreviation{etdr}{ETDR}{expected total discounted reward}
\newabbreviation{mas}{MAS}{multi-agent system}
\newabbreviation{mcts}{MCTS}{Monte-Carlo tree search}
\newabbreviation[longplural={Markov decision processes}]{mdp}{MDP}{Markov decision process}
\newabbreviation[longplural={Nash equilibria}]{nash}{NE}{Nash equilibrium}
\newabbreviation{posg}{POSG}{partially observable stochastic game}
\newabbreviation{td}{TD}{temporal-difference}
\newabbreviation{rts}{RTS}{real time strategy}
\newabbreviation{dec-pomdp}{Dec-POMDP}{decentralised partially observable \gls{mdp}}

% Other
\newabbreviation{afit}{AFIT}{Air Force Institute of Technology}
\newabbreviation{asic}{ASIC}{application specific integrated circuit}
\newabbreviation{api}{API}{application programming interface}
\newabbreviation{cots}{COTS}{commercial off-the-shelf}
\newabbreviation{dod}{DoD}{Department of Defense}
\newabbreviation{darpa}{DARPA}{Defense Advanced Research Projects Agency}
\newabbreviation{isr}{ISR}{intelligence, surveillance, and reconnaissance}
\newabbreviation{kl}{KL}{Kakade-Langford}
\newabbreviation{lidar}{LIDAR}{laser imaging, detection, and ranging}
\newabbreviation[shortplural={UAS}]{uas}{UAS}{unmanned aicraft system}
\newabbreviation{sota}{SOTA}{state of the art}
\newabbreviation{offset}{OFFSET}{OFFensive Swarm-Enabled Tactics}

