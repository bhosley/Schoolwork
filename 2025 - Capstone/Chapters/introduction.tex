\section{The Promise and Challenge of Autonomous Multi-Agent Systems}%
\label{sec:intro_motivation}

In August 2023, Deputy Secretary of Defense Kathleen Hicks announced the 
\emph{Replicator Initiative}, signaling a strategic shift toward fielding 
autonomous systems at scale~\cite{robertson2023,zotero-2656}. 
Unlike previous efforts focused on bespoke military platforms, 
\emph{Replicator} aims to leverage commercial technologies; 
an approach partly inspired by the demonstrated effectiveness of 
\gls{cots} \glspl{uas} during the conflict in Ukraine~\cite{bajak2023a}. 
This initiative reflects a broader recognition that autonomous multi-agent 
systems represent a transformative capability across domains ranging from 
defense to disaster response and agricultural 
automation~\cite{mohddaud2022,hambling2021,rogers2022}.

The technical feasibility of coordinated autonomous swarms has been 
demonstrated through programs such as \gls{darpa}'s \gls{offset} initiative, 
which fielded teams of over 100 autonomous agents in complex urban 
environments~\cite{zotero-2835}. Yet despite these demonstrations, 
a significant gap remains between controlled showcases and operational deployment. 
A 2024 Rand Corporation study predicted that effective, intelligent 
swarms remain years from realization, citing the need for convergent 
advances in communications, manufacturing, \gls{ai}, and usability~\cite{gerstein2024}. 
The study particularly highlighted the difficulty of transitioning from 
\emph{surrogate swarms} (many agents controlled by human operators) 
to fully autonomous systems.

At the heart of this challenge lies a fundamental training problem. 
The computational cost of developing robust multi-agent policies 
scales poorly with team size, creating a bottleneck that limits 
practical deployment~\cite{jin2025,canese2021}. 
Sample complexity in \gls{marl} grows with both the number of 
agents and task difficulty, while the gap between controlled 
benchmarks and operational environments remains 
substantial~\cite{gronauer2022,krouka2022}. Overcoming these 
barriers requires not merely incremental algorithmic improvements, 
but rethinking how we approach the learning problem itself.

Compounding this challenge is the reality that practical swarms 
are rarely homogeneous. Real-world deployments typically involve 
agents with varying sensors, effectors, and capabilities; 
whether mixed drone fleets combining reconnaissance and strike platforms, 
robotic warehouses with specialized material handlers, 
or agricultural systems integrating imaging, spraying, 
and harvesting robots~\cite{rizk2019,hoang2023,amarasinghe2019,carbone2018}. 
This heterogeneity is both a requirement for operational effectiveness 
and a complicating factor for training. \Gls{harl} addresses these 
settings but introduces additional complexity that existing methods 
handle incompletely~\cite{calvo2018,zhong2024}.

This dissertation argues that training efficiency, heterogeneity handling, 
and deployment flexibility in \gls{harl} are fundamentally \emph{representational} 
problems before they are architectural ones. Task structure and heterogeneity 
type determine optimal method selection, and good representational 
design yields robustness as a natural consequence. 
The contributions presented herein develop and validate this thesis 
through systematic investigation of curriculum-based training, 
observation-space homogenization, and comparative evaluation of invariance paradigms.


\section{Multi-Agent Reinforcement Learning Foundations}%
\label{sec:intro_marl}

\Gls{rl} provides the foundational framework for autonomous decision-making under uncertainty. 
In the single-agent setting, the problem is typically formalized as a \gls{mdp}, 
where an agent learns a policy $\pi$ mapping states to actions that maximizes 
expected cumulative reward~\cite{sutton2018}. 
Deep \gls{rl} extends these methods through function approximation 
using neural networks, enabling application to high-dimensional 
state and action spaces~\cite{mnih2015}.

The extension to multiple agents introduces fundamental complications. 
From any single agent's perspective, the environment becomes 
non-stationary as other agents' policies evolve during training~\cite{busoniu2008}. 
This non-stationarity violates the assumptions underlying standard 
\gls{rl} convergence guarantees. The multi-agent setting is typically 
formalized through \glspl{dec-pomdp} for cooperative settings or \glspl{posg} 
for general-sum games, capturing both the partial observability inherent in 
decentralized execution and the strategic interdependence among 
agents~\cite{littman1994,shoham2007}.

The \gls{ctde} paradigm has emerged as the dominant approach for 
cooperative \gls{marl}~\cite{lowe2020,foerster2018,rashid2018}. 
Under \gls{ctde}, agents have access to global information during 
training but must execute using only local observations. 
This paradigm enables coordination learning while maintaining deployability, 
as trained policies can execute in a fully decentralized manner. 
Recent work has questioned whether the centralized component 
is always necessary~\cite{zhou2023}, but \gls{ctde} remains the 
practical standard for most applications.

Within the \gls{ctde} framework, policy gradient methods (particularly \gls{ppo})
have proven remarkably effective~\cite{schulman2017a}. 
\Gls{ppo}'s clipped objective provides stable optimization 
without the computational overhead of trust region methods, 
making it well-suited to the high sample demands of multi-agent learning. 
Extensions including \gls{mappo} and \gls{ippo} have demonstrated 
surprising effectiveness across diverse benchmarks~\cite{yu2022}, 
while \gls{happo} extends these methods to heterogeneous settings 
with theoretical guarantees~\cite{zhong2024}. 
All three contributions in this dissertation build upon 
\gls{ppo}-based methods within the \gls{ctde} paradigm.


\section{The Heterogeneity Challenge}%
\label{sec:intro_heterogeneity}

Heterogeneity in multi-agent systems manifests in two distinct 
forms that require different treatment~\cite{zhong2024,guo2024}. 
\emph{Behavioral heterogeneity} arises when structurally identical 
agents develop different behaviors through independent learning;
a natural outcome when agents occupy different positions or roles 
despite sharing the same capabilities. \emph{Intrinsic heterogeneity}
occurs when agents differ in their sensors, effectors, or internal 
structure, leading to varying observation or action spaces. 
This distinction is not merely taxonomic; it fundamentally 
determines which methods are applicable and effective.

Parameter sharing, where all agents share a single policy network, 
provides substantial benefits for sample efficiency and coordination~\cite{gupta2017}. 
When agents are truly interchangeable, shared parameters reduce the 
learning problem's dimensionality and promote consistent behavior. 
However, parameter sharing implicitly assumes agent interchangeability;
an assumption that breaks down under intrinsic heterogeneity. 
Agents with different observation spaces cannot directly share policies, 
and even behavioral heterogeneity may require agents to learn distinct 
strategies that conflict under full sharing.

Existing approaches to heterogeneity fall into several categories. 
\emph{Explicit agent indication} augments observations with agent identifiers 
(one-hot vectors, learned embeddings) to enable a shared policy to 
condition on agent type~\cite{terry2020}. While effective for behavioral heterogeneity, 
this approach does not resolve structural mismatches in observation or action spaces. 
\emph{Selective parameter sharing} groups similar agents and shares 
parameters within groups~\cite{christianos2021,hao2022}, 
but requires predetermining which agents are similar and 
does not scale gracefully to continuous variation. 
\emph{Separate policies} per agent type maintain distinct networks, 
providing full flexibility but at the cost of \(1/|\Gls{i}|\) storage 
efficiency and no cross-agent generalization~\cite{zhong2024}.

Architectural approaches have sought to handle heterogeneity 
through specialized network structures. Attention mechanisms 
enable policies to weight different observation components 
dynamically~\cite{iqbal2019}. Graph neural networks (\glspl{gnn}) 
treat agents as nodes and can aggregate information across varying 
numbers of neighbors~\cite{yang2021a,liu2020b}. 
The Permutation-Invariant Critic (\gls{pic}) uses graph-based 
aggregation to achieve invariance to agent ordering in the critic, 
enabling scalable centralized training~\cite{liu2020b}. 
These architectural solutions introduce inductive biases 
that may or may not align with the structure of particular problems.


\section{Research Gaps and Dissertation Positioning}%
\label{sec:intro_gaps}

Despite significant progress in \gls{marl} and emerging work in \gls{harl}, 
several critical gaps limit our ability to efficiently train and deploy 
heterogeneous multi-agent systems. This dissertation addresses three interconnected challenges.

\textbf{Curriculum Learning for Team Scaling.} 
Curriculum learning (the principle of training on progressively 
more difficult tasks) has proven effective across machine learning 
domains~\cite{narvekar2020}. In \gls{marl}, natural curricula exist 
along the dimension of team size: smaller teams present simpler 
coordination challenges that may accelerate early learning. 
Yet Smit et al.'s attempt to apply team-scaling curricula in 
\gls{grf} yielded mixed results~\cite{smit2023}, and no systematic 
investigation has characterized \emph{when} and \emph{why} such 
curricula succeed or fail. The role of task structure and 
heterogeneity form in moderating curriculum effectiveness remains unexplored.

\textbf{Parameter Sharing Across Structural Heterogeneity.} 
Current methods for handling intrinsic heterogeneity force a choice 
between flexibility and efficiency. Explicit indication methods do 
not resolve structural mismatches; separate policies scale poorly 
in storage and forgo cross-agent generalization. 
No existing framework enables shared policy parameters across 
agents with genuinely different observation or action spaces 
while preserving the representational capacity to learn agent-specific behaviors.

\textbf{Systematic Comparison of Invariance Paradigms.} 
Both architectural (e.g., \glspl{gnn}) and representational 
(e.g., observation encoding) approaches can achieve invariance 
properties desirable for \gls{harl}, but no controlled comparison 
has established their relative effectiveness. When is the added 
complexity of specialized architectures justified? Can simpler 
representational solutions match or exceed architectural approaches? 
These questions have significant implications for practical system design.


\section{Contributions and Overview}%
\label{sec:intro_contributions}

This dissertation presents three contributions that collectively 
advance the efficiency, flexibility, and deployability of 
heterogeneous multi-agent systems.

\subsection{Contribution 1: Curriculum-Based Team Scaling}

The first contribution investigates whether pretraining 
smaller teams of agents and scaling to target team sizes 
via policy duplication can reduce training cost without 
sacrificing final performance. We introduce \emph{agent-steps} 
(agents $\times$ training steps) as a normalized metric for 
comparing training efficiency across team sizes, enabling 
fair comparison of curriculum strategies.

Experiments span three benchmark environments exhibiting 
different forms of heterogeneity: Waterworld 
(behavioral heterogeneity, low coordination requirements), 
Multiwalker (mild intrinsic heterogeneity through spatial position, 
tight coordination requirements), and 
\gls{lbf} (dynamic intrinsic heterogeneity through 
variable skill levels)~\cite{gupta2017,papoudakis2021}. 
Results demonstrate that task structure critically moderates 
curriculum effectiveness. In Waterworld, pretraining accelerates 
convergence; in Multiwalker, it provides stabilization for 
otherwise failure-prone large teams; in \gls{lbf}, benefits 
are limited and inconsistent due to complex role dynamics.

This contribution establishes that curriculum learning across 
team sizes is not universally beneficial but depends on the 
alignment between pretraining structure and target task demands. 
It also identifies observation-space dimensionality coupling as 
a barrier to policy transfer, motivating the representational 
focus of subsequent contributions.

\subsection{Contribution 2: Implicit Indication via Homogenization}

The second contribution proposes \emph{implicit indication}, 
a representational framework enabling shared policy parameters 
across structurally heterogeneous agents without explicit 
agent identifiers. The core insight is that agent identity 
can be inferred from the pattern of populated observation 
elements rather than requiring explicit labels.

We construct \emph{homogenized observation spaces} spanning 
all agent-specific subspaces. Each agent's capabilities 
correspond to a distinct subset of observation elements; 
unused elements are masked or zeroed. Policies learn to 
condition implicitly on which elements are populated, 
enabling a single network to operate across heterogeneous agents. 
This approach requires \emph{semantic decomposability}: 
observation elements must have consistent meaning across agents.

We develop a custom HyperGrid environment (MiniGrid-based) 
with configurable observation heterogeneity and compare 
implicit indication against \gls{happo} (separate policies per agent type) 
across training configurations varying in observation overlap. 
Results show that implicit indication matches \gls{happo} 
performance with \(1/|\Gls{i}|\) model storage footprint relative to
heterogeneous models. 

Theoretical analysis formalizes conditions under which 
disjoint injective embeddings preserve representability, 
establishing that any collection of functions over heterogeneous 
input spaces can be represented by a single function over the 
homogenized domain~\cite{zaheer2017}.

\subsection{Contribution 3: Architectural versus Representational Approaches}

The third contribution directly compares architectural 
and representational paradigms for handling heterogeneity 
through controlled experiments. We evaluate the \gls{pic}~\cite{liu2020b}, 
representing the architectural approach, against implicit indication 
from Contribution 2.

Using matched network capacities and hyperparameters in the 
HyperGrid environment, we find that while both methods show 
similar training convergence, implicit indication substantially 
outperforms \gls{pic} across all evaluation configurations. 
Complete visibility conditions show mean returns of 9.10 versus 3.89; 
similar gaps persist across intersecting-span, disjoint-span, and 
incomplete observation conditions. Implicit indication also 
demonstrates superior robustness to sensor changes, 
team composition modifications, and zero-shot generalization to novel agent types.

These results suggest that for structurally heterogeneous 
agents in discrete domains with semantically decomposable observations, 
representational solutions can substantially outperform architectural 
alternatives. \Gls{pic}'s graph-based architecture may be better 
suited to environments with richer relational structure, but the 
added complexity does not provide benefits in this domain.

% \subsection{Unifying Thesis}

% Across these three contributions, a consistent theme emerges: 
% \emph{representation design matters as much as algorithmic 
% architecture for enabling efficient, extensible \gls{harl}}. 
% Curriculum effectiveness depends on observation structure; 
% shared policies become possible through representational 
% homogenization; and representational approaches can 
% outperform architectural ones when properly designed. 
% Task structure and heterogeneity type should guide method 
% selection, and good representational design yields robustness 
% as a natural consequence rather than an engineered feature.


\section{Dissertation Structure}%
\label{sec:intro_structure}

The remainder of this dissertation develops these contributions 
and synthesizes their implications for \gls{harl} system design.

\textbf{\Cref{ch:literature_review}} provides comprehensive 
technical background spanning \gls{rl} foundations, 
\gls{marl} paradigms, approaches to scalability and heterogeneity, 
curriculum learning, and permutation invariance. This chapter establishes 
the theoretical and empirical context for the contributions that follow.

\textbf{\Cref{ch:contribution_1}} presents the curriculum-based 
team scaling investigation. We detail the agent-steps framework, 
describe observation schema modifications enabling fixed-architecture 
training across team sizes, and present experimental results across 
Waterworld, Multiwalker, and \gls{lbf}.

\textbf{\Cref{ch:contribution_2}} develops the implicit indication framework. 
We formalize the homogenization procedure, establish theoretical conditions 
for representability preservation, describe the HyperGrid environment, 
and present comparative results against \gls{happo} across multiple 
training and evaluation configurations.

\textbf{\Cref{ch:contribution_3}} provides the controlled comparison 
between architectural and representational approaches. We detail the 
\gls{pic} implementation, present matched experimental conditions, 
and analyze performance differences across training and generalization scenarios.

\textbf{\Cref{ch:conclusion}} synthesizes findings across contributions, 
articulates design principles for \gls{harl} systems, discusses limitations, 
and identifies directions for future research.

The three contributions are structured as standalone studies suitable 
for independent publication while collectively supporting the unifying 
thesis that representational design is central to efficient, flexible \gls{harl}. 
% Cross-chapter connections reinforce this coherence: 
% Contribution 1 identifies observation-space coupling as a barrier that Contribution 2 addresses; 
% Contributions 1 and 3 both investigate training efficiency through complementary lenses; 
% and Contribution 3 directly compares the approach from 
% Contribution 2 against architectural alternatives.
