% Literature Review
\begin{comment}
We intend to use this section for accomplish three things;
\begin{enumerate}
    \item Convince the committee that this is important
    \item Convince the committee that this is an open question
    \item Convince the committee that we understand the current state of the literature and the scope of the intended research. (Implicitly indicating the feasibility of the research)
\end{enumerate}

\section{Key concepts, theories and studies}%
\label{sec:concepts_theories_studies}

\section{Key debates and controversies}%
\label{sec:debates_and_controversies}

\section{Gaps in existing knowledge}%
\label{sec:knowledge_gaps}

Include a lit review table.

\begin{tabular}{ccc}
    Paper & contributions & ref 
\end{tabular}

\end{comment}

% Literature Review ####################%%%%%%%%%%%%%%%%%%%%####################%%%%%%%%%%%%%%%%%%%%
\section{Markov Decision Processes}

\begin{comment}

    \subsection*{Markov Decision Processes}
    
    %Markov Decision Processes (MDPs)
    \glspl*{mdp} are foundational to the field of reinforcement learning. 
    An examination of the literature cited in this dissertation reveals that the terminology and 
    descriptions of MDPs in early papers have significantly influenced the language still used in 
    the field today.
    
\end{comment}


\section{Reinforcement Learning}


\section{Multi-Agent Reinforcement Learning}
\subsection*{Multi-Agent Advantage Decomposition}
\subsection*{Simultaneous Update}
\subsection*{Sequential Update}


\section{Heterogeneous-Agent Reinforcement Learning}


\section{Self-play}


\section{Strategic Collapse}


\section{Key Algorithms}
\subsection*{Multi-Agent DQNs}
\subsection*{Actor-Critic methods} % (lowe2020)
\subsection*{Counterfactual Regret Minimization }
\subsection*{Joint Action Learners}
\subsection*{MAPPO}
\subsection*{HAPPO}
\subsection*{}
\subsection*{}


\begin{comment}
%Additionally, mediated reinforcement learning introduces the concept of mediators to ensure 
%cooperation among self-interested agents, promoting socially beneficial behaviors 
%(Ivanov \& Zisman, 2023).

%Techniques like asymmetric-evolution 
%training have been developed to train agents in asymmetrical multiplayer games, showcasing the 
%capability to handle complex interactions and achieve high performance without human data 
%(Sun et al., 2023).


\cite*{zhong2024} for HARL

\end{comment}