{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest and Localize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "ENTITY = \"no-organization-for-signup\"\n",
    "PROJECT = \"forage-scale-blind\"\n",
    "\n",
    "# Define a function to delete a single run\n",
    "def export_run(run):\n",
    "    try:\n",
    "        # Collect run's summary metrics, configs, and name\n",
    "        summary = run.summary._json_dict\n",
    "        config = {k: v for k, v in run.config.items() if not k.startswith('_')}\n",
    "        name = run.name\n",
    "\n",
    "        # Combine summary and config into a single dictionary\n",
    "        run_data = {**summary, **config}\n",
    "        run_data['name'] = name\n",
    "\n",
    "        # Optionally add more run metadata\n",
    "        run_data['id'] = run.id\n",
    "        run_data['created_at'] = run.created_at\n",
    "        run_data['state'] = run.state\n",
    "\n",
    "        hist = run.history()\n",
    "        hist['id'] = run.id\n",
    "        hist['steps_pretrained'] = run_data['steps_pretrained']\n",
    "        hist['num_agents'] = run_data['num_agents']\n",
    "\n",
    "        return run_data, hist\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error exporting run {run.id}: {e}\"\n",
    "\n",
    "# Initialize W&B API\n",
    "api = wandb.Api()\n",
    "runs = api.runs(f'{ENTITY}/{PROJECT}')\n",
    "\n",
    "# Initialize lists to hold run data and history\n",
    "runs_data = []\n",
    "histories = []\n",
    "\n",
    "# Set up the ThreadPoolExecutor to parallelize the process\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Submit export tasks to the executor\n",
    "    for run_data, history in executor.map(export_run, runs):\n",
    "        runs_data.append(run_data)\n",
    "        histories.append(history)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "runs_df = pd.DataFrame(runs_data)\n",
    "hist_df = pd.concat(histories, keys=[f'run_{i}' for i in range(len(histories))])\n",
    "\n",
    "# Reorder columns so identifying info is at the front\n",
    "cols = ['id', 'name', 'created_at', 'state'] + \\\n",
    "    [col for col in runs_df.columns if col not in \n",
    "     ['id', 'name', 'created_at', 'state']]\n",
    "runs_df = runs_df[cols]\n",
    "\n",
    "# Export the DataFrame to CSV\n",
    "runs_df.to_csv(f\"{PROJECT}.csv\", index=False)\n",
    "hist_df.to_csv(f\"{PROJECT}_history.csv\", index=True)\n",
    "\n",
    "print(f\"Data has been successfully exported to '{PROJECT}.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def baseline_prediction_interval(num_agents, path):\n",
    "    data = []\n",
    "    for p in path:\n",
    "        # Read each table\n",
    "        _df = pd.read_csv(p)\n",
    "        # Filter for number of agents\n",
    "        _df = _df[_df['num_agents']==num_agents]\n",
    "        # Filter for tabula rasa\n",
    "        _df = _df[_df['steps_pretrained']==0]\n",
    "        _df['env_runners/episode_reward_mean'] = (\n",
    "            _df['env_runners/episode_reward_mean']\n",
    "            .div(num_agents)\n",
    "            .replace('NaN',None)\n",
    "            .bfill())\n",
    "        data.append(_df)\n",
    "\n",
    "    seq = (pd.concat(data, ignore_index=True)\n",
    "           .groupby('_step')['env_runners/episode_reward_mean']\n",
    "           )\n",
    "\n",
    "    # Mean and standard deviation per timestep\n",
    "    mean = seq.mean()\n",
    "    std_dev = seq.std()\n",
    "    n = seq.count()\n",
    "\n",
    "    # Calculate the Prediction Interval (PI)\n",
    "    # For large n, using z=1.96 for ~95% coverage. (Central limit theorem)\n",
    "    z = 1.96\n",
    "    margin_of_error = z * std_dev * np.sqrt(1 + 1/n)\n",
    "\n",
    "    x = np.concatenate([mean.index]) * num_agents\n",
    "\n",
    "    return x, mean, margin_of_error\n",
    "\n",
    "\n",
    "def get_avg_retrain(task_agents, path, pre_agents=2):\n",
    "    data = []\n",
    "    for p in path:\n",
    "        # Read each table\n",
    "        _df = pd.read_csv(p)\n",
    "        # Filter for number of agents\n",
    "        _df = _df[_df['num_agents']==task_agents]\n",
    "        # Filter for NON tabula rasa\n",
    "        _df = _df[_df['steps_pretrained']>0]\n",
    "        #_df = _df[_df['steps_pretrained']<200]\n",
    "        data.append(_df)\n",
    "\n",
    "    d1 = (pd.concat(data, ignore_index=True)\n",
    "          .groupby(['steps_pretrained','_step'])['env_runners/episode_reward_mean']\n",
    "          .mean()\n",
    "          .reset_index()\n",
    "          )\n",
    "    \n",
    "    d1['per_agent_erm'] = (d1['env_runners/episode_reward_mean']\n",
    "                           .div(task_agents)\n",
    "                           .replace('NaN',None)\n",
    "                           .bfill())\n",
    "\n",
    "    d1['timestep'] = pre_agents*d1['steps_pretrained'] + task_agents*d1['_step']\n",
    "\n",
    "    return d1\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_avg_retrain(task_agents, path, env, pre_agents=2, show=True, write=True):\n",
    "    retrain_results = get_avg_retrain(task_agents, path)\n",
    "\n",
    "    base_x, base_mean, base_err = baseline_prediction_interval(task_agents, path)\n",
    "\n",
    "    fig = px.line(\n",
    "        retrain_results,\n",
    "        y=\"per_agent_erm\", \n",
    "        x=\"timestep\", color=\"steps_pretrained\", line_group=\"steps_pretrained\",\n",
    "        color_discrete_sequence=px.colors.qualitative.G10, line_shape=\"spline\", \n",
    "        render_mode=\"svg\", \n",
    "        title=f\"{task_agents} Agent {env} with {pre_agents} Agent Pretraining\",\n",
    "        labels={\n",
    "            \"per_agent_erm\" : \"Mean Episode Reward per Agent\", \n",
    "            \"timestep\": \"Agent-steps\",\n",
    "            \"steps_pretrained\": \"Pretraining Length\"})\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=base_x,\n",
    "        y=base_mean-base_err,\n",
    "        line=dict(color='rgba(255,255,255,0)', width=0),\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=base_x,\n",
    "        y=base_mean+base_err,\n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(0,100,80,0.2)',  # semi-transparent fill\n",
    "        line=dict(color='rgba(255,255,255,0)'),\n",
    "        name=f'Baseline:<br>{task_agents} Agent 95%<br>Prediction<br>Interval',\n",
    "        hoverinfo=\"skip\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        y=base_mean, x=base_x,\n",
    "        line_color='rgba(0,100,80,0.5)',\n",
    "        line=dict(dash='dot'),\n",
    "        name=f'Baseline: Mean'\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(width=800, height=500,)\n",
    "    if show:\n",
    "        fig.show()\n",
    "    if write:\n",
    "        fig.write_image(f\"{env}-{task_agents}-agent.png\", width=800, height=500)\n",
    "\n",
    "    return base_x, base_mean, retrain_results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
