% !TeX document-id = {ab4680d0-ba69-455b-a6ba-2898bcb119d6}
\documentclass[12pt]{amsart}
\usepackage[left=0.5in, right=0.5in, bottom=0.75in, top=0.75in]{geometry}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{graphicx}

\usepackage{minted}
\usepackage{xcolor}
\definecolor{LightGray}{gray}{0.92}
% !TeX TXS-program:compile = txs:///pdflatex/[--shell-escape]

\begin{document}
\raggedbottom

\noindent{\large OPER 610 - Linear Programming %
	% Lesson X %
	(Due Mar 7 at 10am)}
\hspace{\fill} {\large B. Hosley}
\bigskip


%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{section}{8}
\setcounter{subsection}{43}
\subsection{}
Consider the linear programming problem given in Exercise 8.42d. 
Starting with the solution \(x_0 = (0.5, 0.5, 1, 0.5)^t\) 
apply the affine scaling algorithm of Exercise 8.43 to solve this problem. 
Show the progress of the iterates with respect to feasibility and 
objective values in Problems \(P\) and \(D\) of Equation (8.28), and 
purify the resulting solution to a pair of optimal primal and dual extreme point 
solutions to Problems \(P\) and \(D\), respectively. 

\noindent
\textit{Use the algorithm as described on pp. 429-430 in the text, not the variant described in Exercise 8.43. \\
Show the progress of iterates (as directed by the text) \\
Do not purify the resulting solution.}

\bigskip

\begin{alignat*}{5}
	\min \quad\   -x_1 & - & 2x_2 &  \\
	\text{s.t.}\qquad 
	x_1 & - &  x_2 & + & x_3 &   &     & = & 1 \\
	x_1 & + & 2x_2 &   &     & + & x_4 & = & 2 \\
	x_1 & , &  x_2 & ,&\ x_3 &, &\ x_4 & \geq & 0. \\
\end{alignat*}

\textbf{Solution:}

To show many iterations of the affine scaling algorithm I have implemented
a small python function. It can be seen in the Appendix, and the output
from that function based on the above system of equations is printed below.

After 20 iterations the "close-enough" that I have found is
\(x_1=0.61196484 \) and
\(x_2=0.67985277 \).

It appears that the destiny of both of these variables will lead eventually to
\(2/3\) for both. When solved by inspection, I had predicted \(x_1=0, x_2=1\)
which happens to have the same objective function, assuming that the algorithm's
objective will converge on the ever-closer \(2\). With this assumption we
thus conclude that this system has multiple optima.

I found the implementation of this algorithm to be significantly more pleasant
than implementing Karmarkar's algorithm.

\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
bgcolor=LightGray,
fontsize=\footnotesize,
]{python}
c = np.array([-1,-2,0,0])
A = np.array([[ 1,-1, 1, 0],[ 1, 2, 0, 1]])
x_0 = np.array([0.5,0.5,1,0.5])

affineScale(c,A,x_0,lam_0=0.25,max_iter=20)
\end{minted}

\textbf{Output:}

\begin{minted}{text}
Iteration:                      x_k / y_k:                      Objective Value:
     1      x: [0.5125     0.51964286 1.00714286 0.44821429] 
            y: [1.025      1.03928571 1.00714286 0.89642857]   -1.5517857142857143
     2      x: [0.57498137 0.61881254 1.04383117 0.18739355] 
            y: [1.12191487 1.190842   1.03642811 0.41808918]   -1.8126064546021394
     3      x: [0.58704252 0.63860322 1.0515607  0.13575104] 
            y: [1.02097659 1.0319817  1.00740496 0.72441684]   -1.864248959982211
     4      x: [0.59341122 0.64910428 1.05569306 0.10838022] 
            y: [1.01084878 1.0164438  1.00392974 0.79837486]   -1.8916197818222678
     5      x: [0.59747855 0.65582647 1.05834792 0.0908685 ] 
            y: [1.00685415 1.0103561  1.0025148  0.83842333]   -1.90913149609188
     6      x: [0.60034    0.66056238 1.06022238 0.07853524] 
            y: [1.0047892  1.00722128 1.00177112 0.86427355]   -1.921464755365538
     7      x: [0.6024782  0.66410467 1.06162647 0.06931246] 
            y: [1.00356166 1.00536254 1.00132433 0.88256496]   -1.930687544746886
     8      x: [0.60414399 0.66686625 1.06272226 0.06212351] 
            y: [1.00276489 1.00415835 1.00103218 0.89628202]   -1.93787649291638
     9      x: [0.60548226 0.66908605 1.06360379 0.05634565] 
            y: [1.00221515 1.0033287  1.0008295  0.90699403]   -1.9436543499129435
     10     x: [0.6065832  0.67091295 1.06432975 0.0515909 ] 
            y: [1.00181829 1.00273045 1.00068255 0.91561457]   -1.9484091016045482
     11     x: [0.60750617 0.67244506 1.06493889 0.04760371] 
            y: [1.00152159 1.00228362 1.00057232 0.92271532]   -1.952396287450965
     12     x: [0.60829198 0.67374985 1.06545787 0.04420833] 
            y: [1.0012935  1.00194036 1.00048733 0.928674  ]   -1.9557916696450885
     13     x: [0.60896967 0.67487538 1.06590571 0.04127957] 
            y: [1.00111409 1.00167055 1.00042033 0.93375103]   -1.9587204259272204
     14     x: [0.60956052 0.67585689 1.06629637 0.0387257 ] 
            y: [1.00097025 1.00145436 1.0003665  0.93813221]   -1.961274301759193
     15     x: [0.61008051 0.67672083 1.06664033 0.03647782] 
            y: [1.00085305 1.00127829 1.00032257 0.94195393]   -1.9635221762552821
     16     x: [0.61054186 0.67748748 1.06694562 0.03448317] 
            y: [1.00075622 1.00113289 1.00028622 0.94531869]   -1.9655168313695266
     17     x: [0.61095413 0.67817265 1.06721852 0.03270057] 
            y: [1.00067525 1.00101134 1.00025578 0.94830512]   -1.967299434696614
     18     x: [0.61132486 0.67878887 1.067464   0.03109741] 
            y: [1.00060681 1.00090864 1.00023002 0.95097458]   -1.968902593556646
     19     x: [0.61166012 0.67934618 1.06768606 0.02964751] 
            y: [1.00054842 1.00082105 1.00020802 0.95337573]   -1.97035248750346
     20     x: [0.61196484 0.67985277 1.06788793 0.02832961] 
            y: [1.00049818 1.00074571 1.00018908 0.95554763]   -1.9716703897535068
\end{minted}


\clearpage
{\Large\centering \textbf{Appendix}} 
\vspace{10ex}

\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
bgcolor=LightGray,
fontsize=\footnotesize,
linenos
]{python}
import numpy as np

def affineScale(c,A,x_0,lam_0=1,alpha=0.5, 
	termination_criteria=0.01,max_iter=50):
	print('Iteration:',' '*20,'x_k / y_k:',' '*20,'Objective Value:')
	lam = lam_0
	I = np.eye(len(x_0))
	x_i = x_0
	for k in range(max_iter):
		D_i = np.diag(x_i)
		y_i = np.linalg.inv(D_i)@x_i
		c_bar = c@D_i
		
		c_p = (I - ((A@D_i).T @ np.linalg.inv(A@(D_i@D_i.T)@A.T)@(A@D_i)))@c_bar.T
		d_i = (-D_i)@c_p
		y_j = y_i - lam*c_p
		x_j = x_i + lam*(d_i)
		arr = x_i/(-d_i)
		lammax = np.where(arr > 0, arr, np.inf).argmin()
		
		lam = alpha*lammax
		x_i = x_j
		print(' '*3,'%2i'%(k+1),' '*3, 'x:', x_i, '\n', ' '*9, 'y:', y_j, ' ', c@x_i)
		if np.linalg.norm(c_p) < termination_criteria : break
\end{minted}




\end{document}