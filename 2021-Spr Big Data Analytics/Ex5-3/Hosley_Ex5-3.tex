\documentclass[]{article}
\usepackage{graphicx}
\usepackage{caption}
\graphicspath{ {./images/} }

% Minted
\usepackage[cache=false]{minted}
	\usemintedstyle{vs}
	\usepackage{xcolor}
		\definecolor{light-gray}{gray}{0.97}

% Subsubsection header run along with text.	
\usepackage{titlesec}
\titleformat{\subsubsection}[runin]% runin puts it in the same paragraph
	{\normalfont\bfseries}% formatting commands to apply to the whole heading
	{\thesubsection}% the label and number
	{0.5em}% space between label/number and subsection title
	{}% formatting commands applied just to subsection title
	[]% punctuation or other commands following subsection title

\usepackage{enumitem}
\usepackage{hyperref}

\usepackage[normalem]{ulem}

\title{Big Data Analytics: Exercise 5-3}
\author{Brandon Hosley}
\date{\today}

\begin{document}
\maketitle

\vspace{-1.5em}

Colab Notebook located
\href{https://colab.research.google.com/drive/1vNtxLyW-ZiW-fKm9A9IOu655ZulL9s1E?usp=sharing}{here.}

\vspace{-1.5em}

\section*{Assignment 1: Section 2.4}
\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}
# Show Schema
text_df.printSchema()

# Verify the Count
text_df.count()
\end{minted}
\includegraphics[width=0.8\linewidth]{image1}

\section*{Assignment 2: Section 2.5}

\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}
# Preprocessing (Pipeline)
documentAssembler = DocumentAssembler()\
	.setInputCol("text")\
	.setOutputCol("document")

use = UniversalSentenceEncoder.pretrained(lang="en") \
	.setInputCols(["document"])\
	.setOutputCol("sentence_embeddings")

model_name = 'classifierdl_use_fakenews' # pre-trained model name
document_classifier = ClassifierDLModel.pretrained(model_name)\
	.setInputCols(['document', 
'sentence_embeddings']).setOutputCol("prediction")

nlp_Pipeline = Pipeline(
	stages=[documentAssembler, 
			use,
			document_classifier])
\end{minted}
\includegraphics[width=\linewidth]{image2} 


\section*{Assignment 3: Section 2.6}

\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}
# Training (Pipeline)
empty_df = spark.createDataFrame([['']]).toDF("text")
pipelineModel = nlp_Pipeline.fit(empty_df)
result_df = pipelineModel.transform(text_df)

# Show Schema
result_df.printSchema()
\end{minted}
\includegraphics[width=\linewidth]{image3} 


\section*{Assignment 4: Section 2.7}
\emph{ Do the exercise in section 3.9 }

\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}
# Visualize the results
import pyspark.sql.functions as F
result_df.select(F.explode(F.arrays_zip('prediction.result', 
'document.result')).alias("cols")) \
	.select(F.expr("cols['0']").alias("prediction"),
			F.expr("cols['1']").alias("document")).show(truncate=True)
\end{minted}
\includegraphics[width=\linewidth]{image4}


\section*{Assignment 5: Rewrite news detection for the Trump and Biden tweet dataset}
\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}
import requests
candidates = ['DonaldTrump', 'JoeBiden']
data = {}
for i, c in enumerate(candidates):
	url = "https://raw.githubusercontent.com/gomachinelearning/Blogs/master/" + c + "Tweets.txt"
	req = requests.get(url)
	data[c] = req.text

# check the sizes: Count the number of characters
print("Verify the dictionary variables are not empty. Print total number of characters in the variables:\n")
print("Donald Trump: {} , Joe Biden: {}".format(len(data['DonaldTrump']) ,len(data['JoeBiden'])))

def print_first_n_characters(n):
	if n == -1:
		print('Printing full tweets of each candidate \n'.format(n) )
	else:
		print('\n\nPrinting the first {} characters of tweets of each candidate \n'.format(n) )
	
	print('DONALD TRUMP: \n ' + data['DonaldTrump'][0:n])  
	print('\n\nJOE BIDEN: \n ' + data['JoeBiden'][0:n])

print_first_n_characters(500)
\end{minted}
\includegraphics[width=\linewidth]{image5.1} %\vspace{-1.5em}

\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}\\
import pandas as pd
tweets_df = spark.createDataFrame( \
	pd.DataFrame({"author":'Trump',"text":lst_donald_trump_tweets}).append( \
	pd.DataFrame({"author":'Biden',"text":lst_joe_biden_tweets})))

tweets_df.printSchema()

# Preprocessing (Pipeline)
documentAssembler = DocumentAssembler()\
	.setInputCol("text")\
	.setOutputCol("document")

use = UniversalSentenceEncoder.pretrained(lang="en") \
	.setInputCols(["document"])\
	.setOutputCol("sentence_embeddings")

model_name = 'classifierdl_use_fakenews' # pre-trained model name
document_classifier = ClassifierDLModel.pretrained(model_name)\
	.setInputCols(['document', 
'sentence_embeddings']).setOutputCol("prediction")

nlp_Pipeline = Pipeline(
	stages=[documentAssembler, 
			use,
			document_classifier])
\end{minted}
\includegraphics[width=\linewidth]{image5.2} %\vspace{-1.5em}

\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}\\
# Training (Pipeline)
empty_df = spark.createDataFrame([['']]).toDF("text")
pipelineModel = nlp_Pipeline.fit(empty_df)
result_df = pipelineModel.transform(tweets_df)

# Show Schema
result_df.printSchema()
\end{minted}
\includegraphics[width=\linewidth]{image5.3} %\vspace{-1.5em}


\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}
# Visualize the results
import pyspark.sql.functions as F
result_df.select(F.explode(F.arrays_zip('prediction.result', 
'document.result')).alias("cols")) \
	.select(F.expr("cols['0']").alias("prediction"),
			F.expr("cols['1']").alias("document")).show(truncate=False)
\end{minted}
\includegraphics[width=\linewidth]{image5.4} %\vspace{-1.5em}

As stated in the assignment, the performance of this model appears to be fairly poor. It is likely that this is largely due to the age of the pre-trained model being less capable on modern data.


\section*{Assignment 6: Rewrite news for a different fake and real news dataset}
\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}
from pathlib import Path
import urllib.request
download_path = "./fake_or_real_news.csv.zip"
if not Path(download_path).is_file():
	print("File Not found will download it!")
	url = "https://raw.githubusercontent.com/joolsa/fake_real_news_dataset/master/fake_or_real_news.csv.zip"
	urllib.request.urlretrieve(url, download_path)
else:
	print("File already present.")

!unzip ./fake_or_real_news.csv.zip
\end{minted}
\includegraphics[width=\linewidth]{image6.1} 


\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}
file_location = r"./fake_or_real_news.csv"
file_type = "csv"
# CSV options
infer_schema = "true"
first_row_is_header = "true"
delimiter = ","
news_df = news_df.replace('“','"').replace('”','"')
news_df = spark.read.format(file_type) \
	.option("header", first_row_is_header) \
	.option("inferSchema", infer_schema) \
	.option("multiline", "true") \
	.option("quote", '"') \
	.option("escape", '"') \
	.option("sep", delimiter) \
	.load(file_location)

from pyspark.sql.functions import regexp_replace,col
news_df = news_df.withColumn('text', regexp_replace(col('text'), "\\n", ""))
news_df.count()

news_df.printSchema()
news_df.show(30)
\end{minted}
\includegraphics[width=\linewidth]{image6.2.1}
\includegraphics[width=\linewidth]{image6.2.2}


\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}
# Preprocessing (Pipeline)
documentAssembler = DocumentAssembler()\
	.setInputCol("text")\
	.setOutputCol("document")

use = UniversalSentenceEncoder.pretrained(lang="en") \
	.setInputCols(["document"])\
	.setOutputCol("sentence_embeddings")

model_name = 'classifierdl_use_fakenews' # pre-trained model name
document_classifier = ClassifierDLModel.pretrained(model_name)\
	.setInputCols(['document', 
'sentence_embeddings']).setOutputCol("prediction")

nlp_Pipeline = Pipeline(
	stages=[documentAssembler, 
			use,
			document_classifier])

# Training (Pipeline)
empty_df = spark.createDataFrame([['']]).toDF("text")
pipelineModel = nlp_Pipeline.fit(empty_df)
t_news_df = pipelineModel.transform(news_df)

# Show Schema
t_news_df.printSchema()
\end{minted}
\includegraphics[width=\linewidth]{image6.3.1} 
\includegraphics[width=\linewidth]{image6.3.2} 


\begin{minted}[breaklines,bgcolor=light-gray]{shell-session}
# Visualize the results
import pyspark.sql.functions as F
t_news_df.select("label",
	F.explode(F.arrays_zip('prediction.result', 'document.result')).alias("cols")) \
		.select("label",
				F.expr("cols['0']").alias("prediction"),
				F.expr("cols['1']").alias("document")).show(truncate=True)
\end{minted}
\includegraphics[width=\linewidth]{image6.4} 




\end{document}