teens <- read.csv("C:/Users/Brando/OneDrive/Documents/SchoolWork/Machine Learning/snsdata.csv")
str(teens)
table(teens$gender, useNA = "ifany")
summary(teens$age)
teens$age <- ifelse(teens$age >= 13 & teens$age < 20,teens$age, NA)
summary(teens$age)
# Cleaned Age results. Remove the probably false ages in the data.
summary(teens$female)
teens$female <- ifelse(teens$gender == "F" &!is.na(teens$gender), 1, 0)
summary(teens$female)
table(teens$female)
teens$no_gender <- NA
teens$no_gender <- ifelse(is.na(teens$gender), 1, 0)
table(teens$no_gender)
ave_age <- ave(teens$age, teens$gradyear, FUN =function(x) mean(x, na.rm = TRUE))
teens$age <- ifelse(is.na(teens$age), ave_age, teens$age)
interests <- teens[5:40]
interests_z <- as.data.frame(lapply(interests, scale))
nk = 2:14
set.seed(1)
WSS = sapply(nk, function(k) {kmeans(interests_z, centers=k)$tot.withinss})
plot(nk, WSS, type="l", xlab= "number of k", ylab="within sum of squares")
### Using the plot to find the crook(elbow) to identify the best k
### *Note, choose the value preceding the elbow. In the case of the above, it will be 6.
set.seed(2345)
teen_clusters <- kmeans(interests_z, 6)
teen_clusters$size
teen_clusters$centers
teens$cluster <- teen_clusters$cluster
aggregate(data = teens, age ~ cluster, mean)
aggregate(data = teens, female ~ cluster, mean)
aggregate(data = teens, friends ~ cluster, mean)