\documentclass[12pt]{amsart}
\usepackage[left=0.5in, right=0.5in, bottom=0.75in, top=0.75in]{geometry}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{multirow}

\renewcommand{\thesubsection}{\arabic{subsection}}
\renewcommand{\thesubsubsection}{\quad(\alph{subsubsection})}

\begin{document}
\raggedbottom

\noindent{\large CSCE 832 - Adv. Topics in Statistical ML %
	- Student Lecture }
\hspace{\fill} {\large B. Hosley}
\bigskip


%%%%%%%%%%%%%%%%%%%%%%%
%\setcounter{section}{}
\setcounter{subsection}{-1}
\subsection{Scheduling}

No preference. \\

\subsection{Data Imbalance}

\subsubsection{Overview}
There are many potential issues associated with data that has significant imbalance between classes. 
While the data-level techniques were addressed in the previous course, 
this time we will examine algorithmic-level techniques.

\subsubsection{Relevance}
It is highly probable that students will encounter data imbalance of various sizes,
a survey of different approaches will hopefully point other students in useful directions
for their theses, or in future projects.

\subsubsection{Rationale}
This topic is a continuation of my previous and probably future class project.
While I do not expect that my dissertation with be very focused on imbalance, 
I do expect that the same statistical principles that make imbalance a problem
will similarly be an obstacle within the areas of interest.

\subsubsection{Sources}
\begin{enumerate}
	\item Pre-reading will include\cite{brownlee2015} which is a quality blog post that has a very brief 
	description of the imbalance problem and provides 8 pointers to try to address the problem.
	\item This \cite{zotero-1472} tensorflow article will be useful for building the learning
	activity. It may also serve as a back up pre-reading article, though something a little 
	more direct will be preferable.
	\item The \cite{johnson2019} article is an academic survey of techniques. 
	This has been used as a guide for my own research into the topic and will be made available
	as supplementary reading for those that have the interest.
\end{enumerate}

\subsubsection{Activities}
The coding exercise will likely be comprised of a skeleton code in the style of what 
is normally presented in this course.
The student code may be a segment of implementing and adjusting the parameters 
of threshold moving, cost-sensitive learning, and novel loss functions that address this problem.



\subsection{GANs (or some related sub-topic)}
\subsubsection{Overview}
Training a pair of neural networks, one that generates a synthetic sample and another that classifies
that synthetic example. The pair engage in an 'arms-race' until acceptable synthetic samples are
produced by the generator network.

\subsubsection{Relevance}
GANs have become a fairly ubiquitous tool, even if students never use one in a meaningful capacity,
it is important that a base level of understanding is achieved for today's practitioners;
the increased popularity presents an increased risk of stakeholders requesting this tool to be
implemented at inappropriate time.

\subsubsection{Rationale}
My research interests have taken me in the direction of game theory applications to machine learning.
As a result, adversarial interactions are a natural area of study.

\subsubsection{Sources}
\begin{enumerate}
	\item A slideshow by Ian Goodfellow \cite{goodfellow2016} provides an overview of GANs and provides
	additional context by comparing other generative algorithms. 
	This may make good pre-reading material, or a helpful outline for the in class portion.
	\item 
	\item 
\end{enumerate}

\subsubsection{Activities}
Student coding exercise will likely be something to the effect of taking a small plot of gaussian noise
and generating artificial handwritten number(s) a la the MNIST dataset.



\subsection{Model Explainability}
% Explainability techniques (e.g. Layer-wise Relevance Propagation)
\subsubsection{Overview}
Explaining the inner workings of a model can increase the confidence not only of the stakeholder,
but also the analyst producing the model. For example, decision trees might be considered the gold standard
for explainability, neural networks are a long way off in this regard.

\subsubsection{Relevance}
Many models (especially those of the neural network variety) are frequently referred to as being a black box. 
I believe this often gives the wrong idea of what is occurring in the hidden layers.
Students in this course should recognize that this is an allusion to the currently very difficult 
assignment of meaning to network weights.

\subsubsection{Rationale}
Improving the explainability of a model is likely to be useful in just about all areas of research.
I suspect that the tools that are used by current researchers in the field may prove useful
in the areas of interest that I am exploring. In most cases there will be significant benefits 
being able to isolate or examine certain model segments.

\subsubsection{Sources}
\begin{enumerate}
	\item 
	\item 
	\item 
\end{enumerate}

\subsubsection{Activities}
A viable student activity may be to complete a layer-wise relevance propagation script that returns a heatmap
of the most referenced areas of an image that has been classified.


\subsection{Model Compression}




\end{document}