 @misc{Brownlee_2015, 
    title={8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset}, 
    url={https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/}, 
    abstractNote={Has this happened to you? You are working on your dataset. You create a classification model and get 90\% accuracy immediately. “Fantastic” you think. You dive a little deeper and discover that 90\% of the data belongs to one class. Damn! This is an example of an imbalanced dataset and the frustrating results it can […]}, 
    journal={MachineLearningMastery.com}, author={Brownlee, Jason}, year={2015}, month={Aug}, language={en-US} }
 @article{Ghojogh_Ghodsi_Karray_Crowley_2021, title={Generative Adversarial Networks and Adversarial Autoencoders: Tutorial and Survey}, url={http://arxiv.org/abs/2111.13282}, DOI={10.48550/arXiv.2111.13282}, abstractNote={This is a tutorial and survey paper on Generative Adversarial Network (GAN), adversarial autoencoders, and their variants. We start with explaining adversarial learning and the vanilla GAN. Then, we explain the conditional GAN and DCGAN. The mode collapse problem is introduced and various methods, including minibatch GAN, unrolled GAN, BourGAN, mixture GAN, D2GAN, and Wasserstein GAN, are introduced for resolving this problem. Then, maximum likelihood estimation in GAN are explained along with f-GAN, adversarial variational Bayes, and Bayesian GAN. Then, we cover feature matching in GAN, InfoGAN, GRAN, LSGAN, energy-based GAN, CatGAN, MMD GAN, LapGAN, progressive GAN, triple GAN, LAG, GMAN, AdaGAN, CoGAN, inverse GAN, BiGAN, ALI, SAGAN, Few-shot GAN, SinGAN, and interpolation and evaluation of GAN. Then, we introduce some applications of GAN such as image-to-image translation (including PatchGAN, CycleGAN, DeepFaceDrawing, simulated GAN, interactive GAN), text-to-image translation (including StackGAN), and mixing image characteristics (including FineGAN and MixNMatch). Finally, we explain the autoencoders based on adversarial learning including adversarial autoencoder, PixelGAN, and implicit autoencoder.}, note={arXiv:2111.13282 [cs, eess, stat]}, number={arXiv:2111.13282}, publisher={arXiv}, author={Ghojogh, Benyamin and Ghodsi, Ali and Karray, Fakhri and Crowley, Mark}, year={2021}, month={Nov} }
 @article{Gohel_Singh_Mohanty_2021, title={Explainable AI: current status and future directions}, url={http://arxiv.org/abs/2107.07045}, abstractNote={Explainable Artificial Intelligence (XAI) is an emerging area of research in the field of Artificial Intelligence (AI). XAI can explain how AI obtained a particular solution (e.g., classification or object detection) and can also answer other “wh” questions. This explainability is not possible in traditional AI. Explainability is essential for critical applications, such as defense, health care, law and order, and autonomous driving vehicles, etc, where the know-how is required for trust and transparency. A number of XAI techniques so far have been purposed for such applications. This paper provides an overview of these techniques from a multimedia (i.e., text, image, audio, and video) point of view. The advantages and shortcomings of these techniques have been discussed, and pointers to some future directions have also been provided.}, note={arXiv:2107.07045 [cs]}, number={arXiv:2107.07045}, publisher={arXiv}, author={Gohel, Prashant and Singh, Priyanka and Mohanty, Manoranjan}, 
    year={2021}, 
    month={Jul} 
}
 @article{Goodfellow_2016, 
    title={Generative Adversarial Networks (GANs)}, 
    author={Goodfellow, Ian}, 
    year={2016}, 
    language={en} 
 }
 @article{Johnson_2019, 
    title={Survey on deep learning with class imbalance}, 
    volume={6}, 
    ISSN={2196-1115}, 
    DOI={10.1186/s40537-019-0192-5}, 
    abstractNote={The purpose of this study is to examine existing deep learning techniques for addressing class imbalanced data. Effective classification with imbalanced data is an important area of research, as high class imbalance is naturally inherent in many real-world applications, e.g., fraud detection and cancer detection. Moreover, highly imbalanced data poses added difficulty, as most learners will exhibit bias towards the majority class, and in extreme cases, may ignore the minority class altogether. Class imbalance has been studied thoroughly over the last two decades using traditional machine learning models, i.e. non-deep learning. Despite recent advances in deep learning, along with its increasing popularity, very little empirical work in the area of deep learning with class imbalance exists. Having achieved record-breaking performance results in several complex domains, investigating the use of deep neural networks for problems containing high levels of class imbalance is of great interest. Available studies regarding class imbalance and deep learning are surveyed in order to better understand the efficacy of deep learning when applied to class imbalanced data. This survey discusses the implementation details and experimental results for each study, and offers additional insight into their strengths and weaknesses. Several areas of focus include: data complexity, architectures tested, performance interpretation, ease of use, big data application, and generalization to other domains. We have found that research in this area is very limited, that most existing work focuses on computer vision tasks with convolutional neural networks, and that the effects of big data are rarely considered. Several traditional methods for class imbalance, e.g. data sampling and cost-sensitive learning, prove to be applicable in deep learning, while more advanced methods that exploit neural network feature learning abilities show promising results. The survey concludes with a discussion that highlights various gaps in deep learning from class imbalanced data for the purpose of guiding future research.}, number={1}, journal={Journal of Big Data}, author={Johnson, Justin M. and Khoshgoftaar, Taghi M.}, year={2019}, month={Mar}, pages={27}, language={en} }
 @book{LRP_2021,
    title={Explainable AI with Layer-wise Relevance Propagation},  
    url={https://www.youtube.com/watch?v=-ED-62oU1WY}, 
    year={2021}, 
    month={Feb} 
}
 @misc{shap_intro, 
    title={An introduction to explainable AI with Shapley values - SHAP latest documentation},
    note={\url{https://shap.readthedocs.io/en/latest/example\_notebooks/overviews%
        /An\%20introduction\%20to\%20explainable\%20AI\%20with\%20Shapley\%20values.html}} 
}
 @misc{tf-imbalanced,
    title = {Classification on imbalanced data | TensorFlow Core}, 
    url={\url{https://www.tensorflow.org/tutorials/structured_data/imbalanced_data}}, 
    journal={TensorFlow}, 
    language={en} 
}
 @misc{tf-GAN,
    title = {Deep Convolutional Generative Adversarial Network | TensorFlow Core}, 
    note={\url{https://www.tensorflow.org/tutorials/generative/dcgan}}, 
    journal={TensorFlow}, 
    language={en} 
}
