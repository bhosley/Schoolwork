\chapter{Methodology}
\label{ch:methodology}
\glsresetall

\section{Data Sanitization}

The datasets employed in this study encompass statistics from the 2019 and 2020 seasons, 
juxtaposed with the points per game from the 2020 and 2021 seasons. 
Initial data cleaning ensured the absence of missing values and consistent data types across all columns. 
The dataframe summaries were scrutinized for anomalous instances. 
The notable instance in the 2019 data revealed a player who participated in 17 games within the season. This player was identified as Emmanuel Sanders, who transitioned from the Denver Broncos to the San Francisco 49ers mid-season. While this anomaly was not replicated in 2020, the 2021 season saw the NFL shift to a 17-game standard season, leading to 82 players with similar statistics.

\section{Variable Selection}

In order to gain a deeper understanding of the data, we analyzed the relationship between each feature and the points per game. 
The outcomes of this preliminary analysis are depicted in Figures \ref{app:featuresPPG}. 
This exploration reveals a distinct correlation between specific features and points per game, 
which is contingent on a player's role within the team. 
This observation implies that segregating player positions could be advantageous, 
enabling dimensionality reduction by eliminating unused features. 
A case in point is the passing features; apart from quarterbacks, only one player has a non-zero value, 
illustrating the specificity of certain features to particular positions.

The relationship with the 'teams' feature is not depicted in the presented collection of charts, 
as the initial plots did not exhibit any discernible pattern.
To further investigate this, Figure \ref{fig:teamppgsyearon} provides a comparison of the 
distribution of PPG across teams over the seasons under study.
The teams are arranged in order of their average Per-Player PPG, to ensure a non-arbitrary sequence.
This visualization underscores the lack of valuable insights based on team performance.

Figure \ref{app:positionPlots} presents the plots for each position following the elimination of their constant variables. Further understanding was obtained by examining the correlation between features. Figures \ref{app:positionCorrPlots}, which display the correlation plots, are referenced when discussing correlation-related issues.

Initially, a comprehensive model was constructed for the Quarterbacks to serve as a benchmark. The resulting coefficients are displayed in Table \ref{tab:full_lm_QB}. 
The dredge tool was considered for identifying an optimal model. However, the constraints of the available computational environment rendered full enumeration impractical.
Instead, we employed a step-wise variable selection function that operated bidirectionally and 
utilized the Akaike Information Criterion (AIC) \cite{akaike1998} as the metric. 
Concurrently, Elasticnet regularization was performed. 
The former approach yielded a marginally superior model.
Finally, a Bayesian linear model was implemented, which demonstrated comparable performance to the other two methods.
This procedure was replicated for each player position.











%%%%%  Pre Edit  %%%%%%

Finally, the partial regressions are combined into a singular multiple regression with the position as an interaction term.
The built-in library provided an effective method for practically joining these multiple regressions. 
The resulting coefficients are largely similar, but reduced by the common regression terms.




\section{Influential Variables}

At each step we checked for outliers.
In the first multiple regression there were 26 outliers within the data as measured by mahalanobis distance.
Within the model there were two outliers based on cook's distance.
The outliers reported from the model were recursively dropped until no outliers were identified.
The data set outliers were dropped from a separate version of the model, 
and the new model did not have any new outliers identified.

Between all of these situations, the model developed from the dataset that had the outliers 
based on mahalanobis distance had the best performance based on $R^2$ and Standard Error.

\ref{tab:outliers}




\section{Adequacy Checking}


qqplot.png
residual_plot.png
results_plot.png
results_trunc_plot.png

\section{Model Validation}










Residual standard error: 3.424 on 154 degrees of freedom 
Multiple R-squared:  0.6613,	Adjusted R-squared:  0.5491 
F-statistic: 5.896 on 51 and 154 DF,  p-value: < 2.2e-16







(b) Discuss the methodology, to include variable selection, adequacy checking, model validation, and analysis of influential observations.



