% Specialized command for this section:
\NewDocumentCommand{\glsNewSymbol}{m m m O{} O{#1}}{%
    \newglossaryentry{#1}{%
        text=\ensuremath{#2}, 
        name=\ensuremath{#3}, 
        description={#4},
        sort={#5}, 
        type=symbols, 
        % group={#6}
    }%
    % This function allows me to use the commands: 
    % \gls{x} -> \(x\) and \Gls{x} -> \(X\)
}

% Reals
\glsNewSymbol{reals}{\mathbb{R}}{\mathbb{R}}[Set of all real numbers.]
% Discount factor
\glsNewSymbol{discount}{\gamma}{\gamma}[Discount-rate.]
% States
\glsNewSymbol{s}{s}{S}[Set of states.]
% Actions
\glsNewSymbol{a}{a}{A}[Set of actions.]
% Reward function
\glsNewSymbol{r}{r}{R}[Reward function.]
% Reward value
\glsNewSymbol{g}{g}{G_t}[Return at time \gls{t}.]
% Time steps
\glsNewSymbol{t}{t}{T}[Set of time steps.]
% Policy
\glsNewSymbol{pi}{\pi}{\pi}[Policy (decision-making rule).]
% Transition Probability Matrix
\glsNewSymbol{P}{\textbf{P}}{\textbf{P}}[Probability transition matrix.]
% Action Value
\glsNewSymbol{q}{q}{Q}[Set of state-values or state-value functions.]
\glsNewSymbol{q_pi}{q_\pi}{q_\pi(a|s)}[Value of action \gls{a} given state \gls{s} by policy \gls{pi}.]
\glsNewSymbol{q_*}{q_*}{q_*(a|s)}[True value of state action\gls{a} given \gls{s}.]
% State Value
\glsNewSymbol{v}{v}{V}[Set of action-values or action-value functions.]
\glsNewSymbol{v_pi}{v_\pi}{v_\pi(s)}[value of state \gls{s} given by policy \gls{pi}.]
\glsNewSymbol{v_*}{v_*}{v_*(s)}[True value of state \gls{s}.]
% Step size parameter
\glsNewSymbol{step-size}{\alpha}{\alpha}[Step-size parameter.]

% Observation Space
\glsNewSymbol{o}{o}{o\in\mathcal{O}}[Element \(o\) of Observation space \(\mathcal{O}\).]

% Expected Value
\glsNewSymbol{expRet}{\mathbb{E}}{\mathbb{E}_{\pi}[\cdot]}[Expected return from policy \gls{pi}.]