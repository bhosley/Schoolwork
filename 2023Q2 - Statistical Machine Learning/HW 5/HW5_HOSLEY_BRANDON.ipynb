{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9lAsyeOwFnoX"
   },
   "source": [
    "# CSCE 623 Homework Assignment 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "46d-KBtJJxN1"
   },
   "source": [
    "### Student Name:  <font color=\"red\">LASTNAME, FIRSTNAME</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Yna07rL4Jz43"
   },
   "source": [
    "### Date: <font color=\"red\">May XX, 2022</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving Common Problems\n",
    "\n",
    "Instructions:\n",
    "* Review all provided code before starting your work - this instructor has provided hints and tips throughout the code\n",
    "* This assignment is composed of 3 parts (3 case studies)\n",
    "    * Each part is designed to be a standalone snippet of a machine learning activity which contains flaws\n",
    "    * Your goal is to identify the flaw by performing steps required to diagnose the flaws\n",
    "    \n",
    "* In each case, you will complete several steps\n",
    "    * CODE CELL (diagnostics): Write code to diagnose the problem and produce evidence of the issue (e.g. print statements, tables, and graphs).  \n",
    "    (IMPORTANT - Even if you can see the flaw directly in the provided code you must include code here to demonstrate the flaw to show evidence of it - failing to do so will result in not achieving full score on the assignment.)\n",
    "    * MARKDOWN CELL: Describe the problem and how to solve it in a markdown cell (English text)\n",
    "    * CODE CELL (solution): Solve the issues so the ML task works properly\n",
    "    \n",
    "* Additional Requirements / Considerations\n",
    "    * While you may inspect the performance on the test set during diagnosis, you should not use the test set to fix the issue.  All decisionmaking (e.g. hyperparameter selection) should be conducted on the non-test set.\n",
    "    * Some form of validation such as validation, crossvalidation or LOOCV should be used for hyperparameter tuning (dont just tune on the training set)\n",
    "    * Ensure your choices for hyperparameter decisions and rationale for using them are displayed/explained in code and/or markdown cells\n",
    "    * Make decisions algorithmically (avoid hardcoding values)\n",
    "\n",
    "* Remember to restart the kernel and rerun all cells before submitting the assignment\n",
    "* Submit only the Jupyter Notebook (.ipynb) file - do not submit the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Note... not all of these are used...\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "from math import factorial\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_validate,  cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, average_precision_score, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, roc_auc_score, RocCurveDisplay \n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "#warnings.filterwarnings(action='once')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL STUDENT CODING: If you need any imports, code them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### ------- EXTRA STUDENT IMPORTS ------------\n",
    "\n",
    "\n",
    "######### ------- END STUDENT IMPORTS ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions provided by instructor\n",
    "\n",
    "def data_explore(df):\n",
    "    \n",
    "\n",
    "    display(md('Data Statistics:'))\n",
    "    display(df.describe())\n",
    "    display(md('Class 0 Statistics:'))\n",
    "    display(df.loc[df.Class==0,:].describe())\n",
    "    display(md('Class 1 Statistics:'))\n",
    "    display(df.loc[df.Class==1,:].describe())\n",
    "    display(md('Covariance of Class 0:'))\n",
    "    display(df.loc[df.Class==0,['X1','X2']].cov())\n",
    "    display(md('Covariance of Class 1:'))\n",
    "    display(df.loc[df.Class==1,['X1','X2']].cov())\n",
    "    sns.pairplot(df, hue=\"Class\", height=5)\n",
    "    df.loc[df.Class==0,:].hist(grid=False, layout=(1,3), figsize=(12,4));\n",
    "    df.loc[df.Class==1,:].hist(grid=False, layout=(1,3), figsize=(12,4));\n",
    "    \n",
    "\n",
    "    \n",
    "def predict_probs(models, X):\n",
    "    \"\"\" Returns a dictionary of predicted proability vectors using models stored in the input dictionary 'models' on the feature data 'X'\n",
    "    params:  \n",
    "    models - a dictionary of fitted classification models with key equal to the name of the model\n",
    "    X - the values of a dataset obtained\"\"\"\n",
    "    predicts = {}\n",
    "    \n",
    "    for key, model in models.items():\n",
    "        predicts[key] = model.predict_proba(X)\n",
    "    return predicts    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "# CASE 1\n",
    "\n",
    "The aspiring machine learning novice is trying to build a simple logistic regression classifier to fit a 2-feature, 2 class dataset, but the outcome is not as expected... you must rescue them from their uncertain fate!\n",
    "\n",
    "------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1 - Load data & explore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "# c1_df = pd.read_csv(\"c1_data.csv\")\n",
    "c1_df = pd.read_csv('c1_data.csv', header=0, names=['X1','X2','Class'], index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "#visualize/explore the dataset\n",
    "data_explore(c1_df)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Case 1 - Split test & non-test, fit a model and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test & training\n",
    "tngfrac = 0.75  # 25 percent of data used for test, rest for non-test\n",
    "tngqty = np.ceil(tngfrac*len(c1_df)).astype(int)\n",
    "c1_non_test_df, c1_test_df= c1_df[:tngqty], c1_df[tngqty:]\n",
    " \n",
    "\n",
    "#fit a model\n",
    "c1_model = LogisticRegression()\n",
    "feature_cols = ['X1','X2']\n",
    "c1_model.fit(c1_non_test_df[feature_cols],c1_non_test_df.Class)\n",
    "\n",
    "#check performance on non-test set\n",
    "non_test_cv_scores = cross_val_score(c1_model, c1_non_test_df[feature_cols], c1_non_test_df.Class, cv=5)\n",
    "print(\"\\n\\n\\nNon-test mean accuracy from 5-fold CV\", np.mean(non_test_cv_scores))\n",
    "\n",
    "#eval performance on test set\n",
    "yhat = c1_model.predict(c1_test_df[feature_cols])\n",
    "test_score = c1_model.score(c1_test_df[feature_cols], c1_test_df['Class'])\n",
    "print(\"\\nTest set accuracy:\", test_score)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1 ISSUE & TASK:\n",
    "\n",
    "The 5-fold crossval performance of a model on the non-training data looks very good, but the test set performance is bad.  \n",
    "\n",
    "Your job is to figure out why.   In the areas below, complete the following steps\n",
    "\n",
    "1.  Use the student code area below to diagnose the problem (use any tools you have learned in the class to do this).  Once you figure out what the problem is, make sure it is clearly presented using code to visualize/print evidence of the problem\n",
    "2.  Use the markdown area after the code cell to describe the problem\n",
    "3.  Solve the problem in the designated code cell after the markdown cell by copying the above cells and fixing errors to resolve the performance gap.   \n",
    "\n",
    "Hint:  Your CV performance and your test performance should be similar and both should be better than chance on this dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1 Diagnostics to discover the problem (STUDENT CODE REQUIRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 1 DIAGNOSTICS\n",
    "\n",
    "# --------- START STUDENT CODE -------------\n",
    "\n",
    "\n",
    "# --------- END STUDENT CODE -------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE 1 Explanation and plan for solution (STUDENT MARKDOWN REQUIRED)\n",
    "\n",
    "In the markdown cell below, describe the problem/mistake the novice made and describe your plan for fixing the issue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>STUDENT ANSWER BELOW</font>   \n",
    "\n",
    "<font color='green'>ANSWER...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE 1 Solution (STUDENT CODE REQUIRED)\n",
    "\n",
    "In this step, fix the problem, run CV make sure you print your mean test set accuracy from crossvalidation.\n",
    "\n",
    "If working correctly, your CV and Test set accuracies should be within a few percent of each other.\n",
    "\n",
    "### Display the mean CV accuracy and Test Set Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 1 SOLUTION\n",
    "\n",
    "myrandstate = 42\n",
    "mean_cv_accuracy = None #placeholder\n",
    "test_accuracy = None #placeholder\n",
    "\n",
    "c1_model = LogisticRegression()\n",
    "feature_cols = ['X1','X2']\n",
    "\n",
    "# --------- START STUDENT CODE -------------\n",
    "\n",
    "#take the steps to fix the problem and fit the c1_model \n",
    "\n",
    "\n",
    "\n",
    "# --------- END STUDENT CODE -------------\n",
    "\n",
    "#eval performance on test set\n",
    "yhat = c1_model.predict(c1_test_df[feature_cols])\n",
    "test_accuracy = c1_model.score(c1_test_df[feature_cols], c1_test_df['Class'])\n",
    "\n",
    "print(\"\\n\\n\\nNon-test mean accuracy from 5-fold CV\", mean_cv_accuracy)\n",
    "print(\"\\nTest set accuracy:\", test_accuracy)\n",
    "print(\"if working well, CV accuracy should be close to test accuracy\")\n",
    "print(\"\\n\\n\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "# CASE 2\n",
    "\n",
    "The aspiring machine learning novice is trying to build a KNN classifier to fit a 200-feature, 2 class dataset, but the 5-fold cv performance is far lower than desired.  Our novice consults with a colleague who brags about being able to achieve over 70% accuracy with KNN on the dataset but the braggart refuses to help the novice.   \n",
    "\n",
    "Only you can save our novice!\n",
    "\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrandstate = 42\n",
    "\n",
    "c2_df = pd.read_csv('c2_data.csv', header=0, index_col=0)\n",
    "\n",
    "#test / non-test split\n",
    "tngfrac = 0.75\n",
    "c2_non_test_df, c2_test_df= train_test_split(c2_df, train_size = tngfrac, stratify=c2_df.Class, random_state=myrandstate)\n",
    "\n",
    "\n",
    "display(c2_non_test_df.describe())\n",
    "\n",
    "\n",
    "#instantiate a model\n",
    "c2_model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "#check performance on non-test set using cross-validation\n",
    "non_test_cv_scores = cross_val_score(c2_model,\n",
    "                                     c2_non_test_df.loc[:, c2_non_test_df.columns != \"Class\"],\n",
    "                                     c2_non_test_df.Class, cv=5)\n",
    "print(\"\\n\\n\\nNon-test mean accuracy from 5-fold CV\", np.mean(non_test_cv_scores))\n",
    "\n",
    "#fit a model\n",
    "c2_model.fit(c2_non_test_df.loc[:, c2_non_test_df.columns != \"Class\"],c2_non_test_df.Class)\n",
    "\n",
    "\n",
    "#eval performance on test set\n",
    "yhat = c2_model.predict(c2_test_df.loc[:, c2_test_df.columns != \"Class\"])\n",
    "test_score = c2_model.score(c2_test_df.loc[:, c2_test_df.columns != \"Class\"], c2_test_df['Class'])\n",
    "print(\"\\nTest set accuracy:\", test_score)\n",
    "print(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CASE 2 DIAGNOSTICS\n",
    "\n",
    "\n",
    "# --------- START STUDENT CODE -------------\n",
    "\n",
    "\n",
    "\n",
    "# --------- END STUDENT CODE -------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE 2 Explanation and Plan for Solution (STUDENT MARKDOWN REQURIED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>STUDENT ANSWER BELOW</font>   \n",
    "\n",
    "<font color='green'>ANSWER...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE 2 Solution (STUDENT CODE REQURIED) \n",
    "\n",
    "Implement your fix to help the novice achieve over 70% accuracy using KNN on the test set.\n",
    "\n",
    "To achive this fit a new model `c2_fixed_model` on the non-test data\n",
    "\n",
    "The model you fit will be evaluated on the test data and should achieve a performance around 70% accuracy\n",
    "\n",
    "### Display the test set accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CASE 2 SOLUTION\n",
    "\n",
    "c2_fixed_model = None  #placeholder for the model you will fit\n",
    "\n",
    "# --------- START STUDENT CODE -------------\n",
    "\n",
    "# take actions and fit a c2_fixed_model that will do well on the test set\n",
    "\n",
    "# --------- END STUDENT CODE -------------\n",
    "\n",
    "# determine test set performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yhat = c2_fixed_model.predict(c2_test_df.loc[:, c2_test_df.columns != \"Class\"])\n",
    "test_accuracy = c2_fixed_model.score(c2_test_df.loc[:, c2_test_df.columns != \"Class\"], c2_test_df['Class'])\n",
    "\n",
    "print(\"\\nTest set accuracy:\", test_accuracy)\n",
    "print(\"\\n\\n\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "# CASE 3\n",
    "\n",
    "The ML Novice is tackling a customer requirement.  The customer wants to make a classifier for a targeting system which has maximally high precision - Ideally, as many possible true targets are found and there are zero false positives.  The catch is that the customer wants to use QDA for this model and that they want a solution which has perfect precision (1) and finds the maximum number of targets when precision is perfect.  Model tuning should happen on the non-test set and performance evaluation/reporting on the test set.\n",
    "\n",
    "Unfortunately, things are not going well for our novice... see if you can help!\n",
    "\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "randstate = 42\n",
    "\n",
    "#load the data\n",
    "c3_df = pd.read_csv('c3_data.csv', header=0, names=['X1','X2','Class'], index_col=0)\n",
    "\n",
    "#split test & nontest\n",
    "c3_non_test_df,c3_test_df = train_test_split(c3_df,test_size=0.5,random_state=randstate, stratify=c3_df.Class)\n",
    "#explore the non-test data\n",
    "data_explore(c3_non_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset the training data into features and labels\n",
    "X = c3_non_test_df.loc[:,['X1','X2']]\n",
    "y = c3_non_test_df.loc[:,['Class']].values.ravel()\n",
    "\n",
    "#instantiate qda model\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "# qda = LinearDiscriminantAnalysis()\n",
    "qda.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "kfold_count = 5\n",
    "\n",
    "non_test_cv_precision=np.mean(cross_val_score(estimator = QuadraticDiscriminantAnalysis(), scoring=make_scorer(precision_score),\n",
    "                                    X=X,\n",
    "                                    y=y,\n",
    "                                    cv=kfold_count))\n",
    "\n",
    "print(\"Non-test set cv precision:\",non_test_cv_precision)\n",
    "\n",
    "\n",
    "#obtain prediction probs on test set using the model fit previously on the non-test data\n",
    "preds_test = qda.predict_proba(c3_test_df.loc[:,['X1','X2']])\n",
    "\n",
    "#classify the prediction probabilities\n",
    "desired_precision = 1.0\n",
    "y_hat_test = (preds_test[:,1]>=desired_precision)*1.0\n",
    "\n",
    "predPos = y_hat_test==1 \n",
    "truePos = predPos&(c3_test_df['Class'].values==1)\n",
    "prec = sum(truePos*1.0)/sum(predPos*1.0)\n",
    "print(\"precision:\", prec) \n",
    "print(\"Test Set predicted positives:\",sum(truePos*1.0))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE 3 Diagnostics (STUDENT CODE REQUIRED)\n",
    "\n",
    "So we can see that the novice's model seems to be unacceptably low precision during CV on the non-test set, but on the test set, the model is not predicting *anything* positive and precision cannot even be computed due to the divide by zero error!  This is bad.  Run diagnostics in the cell below to see if you can discover the problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CASE 3 DIAGNOSTICS\n",
    "\n",
    "\n",
    "# --------- START STUDENT CODE -------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------- END STUDENT CODE -------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE 3 Explanation and Plan for Solution (STUDENT MARKDOWN REQURIED) \n",
    "\n",
    "Describe what you discovered in the diagnostic code you wrote above AND define the plan for how to resolve the issue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>STUDENT ANSWER BELOW</font>   \n",
    "\n",
    "<font color='green'>ANSWER...."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE 3 Solution (STUDENT CODE REQURIRED)\n",
    "\n",
    "In the code cell below, implement a solution which achieves the customer goal of perfect precision with the most possible targets found (maximize true positives).  \n",
    "\n",
    "### Report the precision and number of true positives found in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 3 SOLUTION\n",
    "\n",
    "\n",
    "test_prec = None #placeholder for test set precision\n",
    "test_TP =None #placeholder for test set TRUE POSITIVE count (an integer)\n",
    "\n",
    "X_non_test = c3_non_test_df.loc[:,['X1','X2']].values\n",
    "y_non_test = c3_non_test_df.Class.values\n",
    "\n",
    "X_test = c3_test_df.loc[:,['X1','X2']].values\n",
    "y_test = c3_test_df.Class.values\n",
    "\n",
    "clf = QuadraticDiscriminantAnalysis()  #you will need to train a model of this type\n",
    "\n",
    "# --------- START STUDENT CODE -------------\n",
    "\n",
    "#after fitting a model, evaluate it and compute the test_prec and test_TP on the test set data \n",
    "\n",
    "# --------- END STUDENT CODE -------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Test Set Precision:\", test_prec, \"; Test Set True Positives:\", test_TP)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
