@inproceedings{fouhey2013, 
    address={Sydney, Australia}, 
    title={Data-Driven 3D Primitives for Single Image Understanding}, 
    ISBN={978-1-4799-2840-8}, 
    url={http://ieeexplore.ieee.org/document/6751533/}, 
    DOI={10.1109/ICCV.2013.421}, 
    booktitle={2013 IEEE International Conference on Computer Vision}, 
    publisher={IEEE}, 
    author={Fouhey, David F. and Gupta, Abhinav and Hebert, Martial}, 
    year={2013}, 
    month={Dec}, 
    pages={3392-3399}, 
    language={en}}
@article{isola2018, 
    title={Image-to-Image Translation with Conditional Adversarial Networks}, 
    url={http://arxiv.org/abs/1611.07004}, 
    DOI={10.48550/arXiv.1611.07004}, 
    abstractNote={We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.}, 
    note={arXiv:1611.07004}, 
    number={arXiv:1611.07004}, 
    publisher={arXiv}, 
    author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.}, 
    year={2018}, 
    month={Nov} }
@inbook{tylecek2013, 
    address={Berlin, Heidelberg}, 
    series={Lecture Notes in Computer Science}, 
    title={Spatial Pattern Templates for Recognition of Objects with Regular Structure}, 
    volume={8142}, 
    ISBN={978-3-642-40601-0}, 
    url={http://link.springer.com/10.1007/978-3-642-40602-7_39}, 
    DOI={10.1007/978-3-642-40602-7_39}, 
    abstractNote={We propose a method for semantic parsing of images with regular structure. The structured objects are modeled in a densely connected CRF. The paper describes how to embody speciﬁc spatial relations in a representation called Spatial Pattern Templates (SPT), which allows us to capture regularity constraints of alignment and equal spacing in pairwise and ternary potentials.}, 
    booktitle={Pattern Recognition}, publisher={Springer Berlin Heidelberg}, 
    author={Tylecek, Radim and Sara, Radim}, 
    editor={Weickert, Joachim and Hein, Matthias and Schiele, Bernt}, year={2013}, pages={364–374}, collection={Lecture Notes in Computer Science}, language={en} }
 @inproceedings{yang2015, 
    address={Boston, MA, USA}, title={A large-scale car dataset for fine-grained categorization and verification}, 
    ISBN={978-1-4673-6964-0}, 
    url={http://ieeexplore.ieee.org/document/7299023/}, 
    DOI={10.1109/CVPR.2015.7299023}, 
    booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, publisher={IEEE}, author={Yang, Linjie and Luo, Ping and Loy, Chen Change and Tang, Xiaoou}, year={2015}, month={Jun}, pages={3973–3981}, language={en} }
 @article{Yohannes_Lin_Shih_Thaipisutikul_Enkhbat_Utaminingrum_2023, 
    title={An Improved Speed Estimation Using Deep Homography Transformation Regression Network on Monocular Videos}, volume={11}, ISSN={2169-3536}, DOI={10.1109/ACCESS.2023.3236512}, abstractNote={Vehicle speed estimation is one of the most critical issues in intelligent transportation system (ITS) research, while defining distance and identifying direction have become an inseparable part of vehicle speed estimation. Despite the success of traditional and deep learning approaches in estimating vehicle speed, the high cost of deploying hardware devices to get all related sensor data, such as infrared/ultrasonic devices, Global Positioning Systems (GPS), Light Detection and Ranging (LiDAR systems), and magnetic devices, has become the key barrier to improvement in previous studies. In this paper, our proposed model consists of two main components: 1) a vehicle detection and tracking component – this module is designed for creating reliable detection and tracking every specific object without doing calibration; 2) homography transformation regression network – this module has a function to solve occlusion issues and estimate vehicle speed accurately and efficiently. Experimental results on two datasets show that the proposed method outperforms the state-of-the-art methods by reducing the mean square error (MSE) metric from 14.02 to 6.56 based on deep learning approaches. We have announced our test code and model on GitHub with https://github.com/ervinyo/Speed-Estimation-Using-Homography-Transformation-and-Regression-Network.}, 
    journal={IEEE Access}, author={Yohannes, Ervin and Lin, Chih-Yang and Shih, Timothy K. and Thaipisutikul, Tipajin and Enkhbat, Avirmed and Utaminingrum, Fitri}, year={2023}, 
    pages={5955–5965} }
