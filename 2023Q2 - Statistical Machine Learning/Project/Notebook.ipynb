{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ipydex.displaytools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer, \n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay,\\\n",
    "    precision_score,recall_score, f1_score,roc_auc_score,roc_curve, balanced_accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>Diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  HighChol  CholCheck   BMI  Smoker  HeartDiseaseorAttack  \\\n",
       "0   4.0  1.0       0.0        1.0  26.0     0.0                   0.0   \n",
       "1  12.0  1.0       1.0        1.0  26.0     1.0                   0.0   \n",
       "2  13.0  1.0       0.0        1.0  26.0     0.0                   0.0   \n",
       "3  11.0  1.0       1.0        1.0  28.0     1.0                   0.0   \n",
       "4   8.0  0.0       0.0        1.0  29.0     1.0                   0.0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  HvyAlcoholConsump  GenHlth  MentHlth  \\\n",
       "0           1.0     0.0      1.0                0.0      3.0       5.0   \n",
       "1           0.0     1.0      0.0                0.0      3.0       0.0   \n",
       "2           1.0     1.0      1.0                0.0      1.0       0.0   \n",
       "3           1.0     1.0      1.0                0.0      3.0       0.0   \n",
       "4           1.0     1.0      1.0                0.0      2.0       0.0   \n",
       "\n",
       "   PhysHlth  DiffWalk  Stroke  HighBP  Diabetes  \n",
       "0      30.0       0.0     0.0     1.0       0.0  \n",
       "1       0.0       0.0     1.0     1.0       0.0  \n",
       "2      10.0       0.0     0.0     0.0       0.0  \n",
       "3       3.0       0.0     0.0     1.0       0.0  \n",
       "4       0.0       0.0     0.0     0.0       0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../Datasets/diabetes_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration Curtesy of Solafa Jobi\n",
    "# at https://www.kaggle.com/code/solafajobi/diabetes-perfect-prediction\n",
    "\n",
    "#select variables that are medically likely to predict diabetes\n",
    "dm = df[[\"Age\",\"Sex\",\"HighChol\",\"BMI\",\"Smoker\",\"PhysActivity\",\"PhysHlth\",\"Fruits\",\"Veggies\",\"HvyAlcoholConsump\",\"Stroke\",\"HighBP\",\"Diabetes\"]]\n",
    "dm.head()\n",
    "#check unique values\n",
    "unique_values = {}\n",
    "for col in dm.columns:\n",
    "    unique_values[col] = dm[col].value_counts().shape[0]\n",
    "pd.DataFrame(unique_values, index=['unique value count']).transpose()\n",
    "#check frequency of all values in the column\n",
    "# All data columns except for color\n",
    "feature_cols = [x for x in dm.columns if x not in 'stroke']\n",
    "plt.figure(figsize=(25,35))\n",
    "# loop for subplots\n",
    "for i in range(len(feature_cols)):\n",
    "    plt.subplot(8,5,i+1)\n",
    "    plt.title(feature_cols[i])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.hist(dm[feature_cols[i]],color = \"deepskyblue\")\n",
    "plt.tight_layout()\n",
    "#we should drop the columns with very small categories- (HvyAlcoholConsump and stroke)\n",
    "dm.drop(['HvyAlcoholConsump','Stroke'], axis=1, inplace=True)\n",
    "#check correlation of other columns with diabetes column\n",
    "dm.drop('Diabetes', axis=1).corrwith(dm.Diabetes)\\\n",
    "    .plot(kind='bar', grid=True, figsize=(10, 6), title=\"Correlation with Diabetes\",color=\"deepskyblue\")\n",
    "#variables with correlation less than 0.1 are Sex, Smoker, Fruits, Veggies\n",
    "# Correlation between any two features\n",
    "# check for possible co-variates\n",
    "sns.set(rc = {'figure.figsize':(10,10)})\n",
    "sns.heatmap(dm.corr(),vmin=-1, vmax=1, annot = True, fmt='.1g',cmap= 'coolwarm')\n",
    "#drop the variables with low correlations Sex, Smoker, Fruits, Veggies\n",
    "dm.drop(['Sex','Smoker','Fruits','Veggies'], axis=1, inplace=True)\n",
    "#narrowed down to 6 possible determinants \n",
    "#determine which predictors are more useful\n",
    "# Bivariate bar plot for categorical variables\n",
    "features = [x for x in dm.columns if x not in ['Age','BMI','PhysHlth','Diabetes']]\n",
    "plt.figure(figsize = (30,23))\n",
    "plt.suptitle('Diabetes by categorical features')\n",
    "#subplots\n",
    "for i in enumerate(features):\n",
    "    plt.subplot(2,4, i[0]+1)   \n",
    "    x = sns.countplot(data=dm, x=i[1], hue='Diabetes', palette = ['deepskyblue','crimson'])\n",
    "    for z in x.patches:\n",
    "      x.annotate('{:.1f}'.format((z.get_height()/dm.shape[0])*100)+'%',(z.get_x()+0.25, z.get_height()+0.01))\n",
    "#for numeric variables\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.displot(x='BMI', col='Diabetes' , data = dm, kind=\"kde\" ,color = 'deepskyblue')\n",
    "plt.figure(figsize=(12,20))\n",
    "sns.displot(data=dm,col='Diabetes',x='Age',color='deepskyblue')\n",
    "#Check skewness\n",
    "#can only be checked for numeric data\n",
    "dm_skew = dm[['Age','BMI','PhysHlth']]\n",
    "skew = pd.DataFrame(dm_skew.skew())\n",
    "skew.columns = ['skew']\n",
    "skew['too_skewed'] = skew['skew'] > .75\n",
    "skew\n",
    "#BMI and PhysHlth are skewed. It needs to be transformed\n",
    "#Scaling the data for features selection using the MinMaxScaler method.\n",
    "#only numeric variables apply here\n",
    "mms = MinMaxScaler()\n",
    "dm[['BMI']] = mms.fit_transform(dm[['BMI']])\n",
    "dm[['Age']] = mms.fit_transform(dm[['Age']])\n",
    "dm[['PhysHlth']] = mms.fit_transform(dm[['PhysHlth']])\n",
    "dm.head()\n",
    "\n",
    "\n",
    "#Features selection -step 1\n",
    "#1. Define X,y\n",
    "y = (dm['Diabetes']).astype(int)\n",
    "X = dm.loc[:, dm.columns != 'Diabetes']  # everything except \"Diabetes\"\n",
    "#step 2\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "plt.figure(figsize=(8,6))\n",
    "feat_importances.nlargest(6).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "#method 2   \n",
    "\n",
    "#apply SelectKBest class to extract top 5 best features   #Do this before quantile transformation\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=5)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(6,'Score'))  #print 5 best features\n",
    "\n",
    "#Method 3\n",
    "\n",
    "#Create a logistic regression classifier\n",
    "lr = LogisticRegression()\n",
    "# Create an EFS object\n",
    "efs = EFS(estimator=lr,        # Use logistic regression as the classifier/estimator\n",
    "          min_features=1,      # The minimum number of features to consider is 1\n",
    "          max_features=5,      # The maximum number of features to consider is 5\n",
    "          scoring='accuracy',  # The metric to use to evaluate the classifier is accuracy \n",
    "          cv=4)                # The number of cross-validations to perform is 4\n",
    "\n",
    "# Train EFS with our dataset\n",
    "efs = efs.fit(X, y)\n",
    "# Print the results\n",
    "print('Best accuracy score: %.2f' % efs.best_score_) # best_score_ shows the best score \n",
    "print('Best subset (indices):', efs.best_idx_)       # best_idx_ shows the index of features that yield the best score \n",
    "print('Best subset (corresponding names):', efs.best_feature_names_) # best_feature_names_ shows the feature names\n",
    "#recheck the skew\n",
    "dm_skew = dm[['Age','BMI','PhysHlth']]\n",
    "skew = pd.DataFrame(dm_skew.skew())\n",
    "skew.columns = ['skew']\n",
    "skew['too_skewed'] = skew['skew'] > .75\n",
    "skew\n",
    "#use quantile tranformation\n",
    "qt = QuantileTransformer(n_quantiles=500, output_distribution='normal')\n",
    "dm[['BMI']] = qt.fit_transform(dm[['BMI']])\n",
    "dm[['PhysHlth']] = qt.fit_transform(dm[['PhysHlth']])\n",
    "#recheck the skew\n",
    "dm_skew = dm[['Age','BMI','PhysHlth']]\n",
    "skew = pd.DataFrame(dm_skew.skew())\n",
    "skew.columns = ['skew']\n",
    "skew['too_skewed'] = skew['skew'] > .75\n",
    "skew\n",
    "dm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building Curtesy of Solafa Jobi\n",
    "# at https://www.kaggle.com/code/solafajobi/diabetes-perfect-prediction\n",
    "\n",
    "#Data splitting\n",
    "\n",
    "y = (dm['Diabetes']).astype(int)\n",
    "X = dm.loc[:, dm.columns != 'stroke']  # everything except \"stroke\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "\n",
    "#Predict with Decision tree, KNN and Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# defining parameter range\n",
    "param_grid = {'n_neighbors': [1,3,5,7,9,11,13,15,17,19],  #odd numbers because there are 2 classes in target coulmn\n",
    "              'weights': ['distance', 'uniform']}  \n",
    "gridKNN = GridSearchCV(KNeighborsClassifier(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "gridKNN.fit(X_train, y_train)\n",
    "print(gridKNN.best_params_)\n",
    "\n",
    "#predict with the best parameter\n",
    "y_pred_test = gridKNN.predict(X_test)\n",
    "y_pred_train = gridKNN.predict(X_train)\n",
    "\n",
    "#Check accuracy and overfitting\n",
    "print(accuracy_score(y_train, y_pred_train))\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "#confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred_test, labels=gridKNN.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=gridKNN.classes_)\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "disp.plot(cmap=plt.cm.Blues) \n",
    "plt.grid(which='major')     #remove cell gridlines\n",
    "plt.gcf().set_size_inches(6, 6)   # Adjust the size of the plot\n",
    "plt.show()\n",
    "\n",
    "#model metrics\n",
    "\n",
    "#function that get y_test and calculate into df all the relevant metric\n",
    "def train_evaluate_model(y_test):\n",
    "    #fit the model instance \n",
    "    predictions = y_pred_test # calculate predictions\n",
    "\n",
    "    #compute metrics for evaluation\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "    auc = roc_auc_score(y_test, predictions)\n",
    "\n",
    "    #create a dataframe to visualize the results\n",
    "    eval_df = pd.DataFrame([[accuracy, f1, precision, recall, balanced_accuracy, auc]], columns=['accuracy', 'f1_score', 'precision', 'recall', 'balanced_accuracy', 'auc'])\n",
    "    return eval_df\n",
    "\n",
    "#model metrics\n",
    "\n",
    "results = train_evaluate_model(y_test)\n",
    "results.index = ['K Nearest Neighbors - Method 1']\n",
    "results.style.background_gradient(cmap = sns.color_palette(\"blend:green,red\", as_cmap=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt = dt.fit(X_train, y_train)\n",
    "\n",
    "#dt = DecisionTreeClassifier(random_state=42)\n",
    "dt = dt.fit(X_train, y_train)\n",
    "\n",
    "# defining parameter range\n",
    "param_grid = {'max_depth':range(1, dt.tree_.max_depth+1, 2),\n",
    "              'max_features': range(1, len(dt.feature_importances_)+1)}  \n",
    "gridDT = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, n_jobs=-1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "gridDT.fit(X_train, y_train)\n",
    "print(gridDT.best_params_)\n",
    "\n",
    "y_pred_test = gridDT.predict(X_test)\n",
    "y_pred_train = gridDT.predict(X_train)\n",
    "print(accuracy_score(y_train, y_pred_train))\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "#confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred_test, labels=gridDT.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=gridDT.classes_)\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "disp.plot(cmap=plt.cm.Blues) \n",
    "plt.grid(which='major')     #remove cell gridlines\n",
    "plt.gcf().set_size_inches(6, 6)   # Adjust the size of the plot\n",
    "plt.show()\n",
    "\n",
    "resultsDT = train_evaluate_model(y_test)\n",
    "resultsDT.index = ['Decision Trees - Method 2']\n",
    "results = results.append(resultsDT)\n",
    "results.style.background_gradient(cmap = sns.color_palette(\"blend:red,green\", as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(oob_score=True, \n",
    "                            random_state=42, \n",
    "                            warm_start=True,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "# defining parameter range\n",
    "param_grid = {'n_estimators':[15, 20, 30, 40, 50, 100, 150, 200, 300, 400]\n",
    "              }  \n",
    "gridRF = GridSearchCV(RF, param_grid)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "gridRF.fit(X_train, y_train)\n",
    "print(gridRF.best_params_)\n",
    "\n",
    "y_pred_test = gridRF.predict(X_test)\n",
    "y_pred_train = gridRF.predict(X_train)\n",
    "print(accuracy_score(y_train, y_pred_train))\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "#confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred_test, labels=gridRF.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=gridRF.classes_)\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "disp.plot(cmap=plt.cm.Blues) \n",
    "plt.grid(which='major')     #remove cell gridlines\n",
    "plt.gcf().set_size_inches(6, 6)   # Adjust the size of the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsRF = train_evaluate_model(y_test)\n",
    "resultsRF.index = ['Random Forest - Method 3']\n",
    "results = results.append(resultsRF)\n",
    "results.style.background_gradient(cmap = sns.color_palette(\"blend:red,green\", as_cmap=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
