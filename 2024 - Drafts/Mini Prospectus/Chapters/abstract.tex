The Replicator Initiative, announced by the U.S. Department of Defense in 2023, 
aims to deploy all-domain attritable autonomous (ADA2) systems leveraging 
commercial off-the-shelf technologies to address production challenges in 
great-power competition. Despite these strategic efforts, effective and 
intelligent swarms remain years away. This gap underscores the need for 
advanced training methodologies for autonomous agents 
that can generalize across variable team sizes and hardware configurations, 
crucial for deploying flexible and resilient systems in dynamic environments.

This research focuses on developing scalable and efficient 
\gls{marl} and \gls{harl} algorithms to address these challenges. 
The methodology includes evaluating the generalizability of 
\gls{marl} and \gls{harl} algorithms, 
assessing the impact of non-stationarity introduced by adversarial agents, 
and exploring auto-curricular methods for dynamic curriculum design. 
By leveraging the RLlib framework, the study will conduct comprehensive 
evaluations across various scenarios, providing insights into training time, 
performance consistency, and the adaptability of agents to different team 
compositions and competitive environments.

The anticipated outcomes include establishing a baseline for 
\gls{marl} and \gls{harl} algorithms, enhancing training methodologies 
through role variability and observation space transformations, 
and contributing to scalable solutions applicable to real-world 
scenarios such as robotic swarms and autonomous vehicle coordination. 
The research aims to advance the understanding and effectiveness 
of multi-agent systems, pushing the boundaries of current \gls{marl} 
research towards more robust and adaptable autonomous systems.

\glsresetall