\documentclass[answers]{exam}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{booktabs}
\usepackage{diagbox}

\usepackage{calligra}

\DeclareMathAlphabet{\mathcalligra}{T1}{calligra}{m}{n}
\DeclareFontShape{T1}{calligra}{m}{n}{<->s*[2.2]callig15}{}

\usepackage[scr=rsfs]{mathalpha}

\title{STAT 587 - Introduction to Probability and Statistics%
	\\ Homework 6}
\author{Brandon Hosley}
\date{\today}

\begin{document}
\maketitle
\begin{questions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\begin{ Question 1}	  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\question 
Let \(X_1,\dots,X_n\) be a random sample of size \(n\) from an exponential distribution, 
\(X_i\sim\operatorname{Shifted Exponential}(\beta=1,\eta)\). 
A test of \(H_0\ :\,\eta\leq\eta_0\) vs. \(H_a\ :\,\eta>\eta_0\)
is desired, based on \(X_{(1)}\). 
Find a critical region of size \(\alpha\) of the form \(\{x_{(1)}\geq c\}\).
\begin{solution}
	% Bain and Engelhardt Example 12.7.3 pg 414
	Referencing Theorem 12.7.1: \\
	Test for \(\alpha \rightarrow H_0:\eta\leq\eta_0\) and \(H_1: \eta>\eta_0\) 
	rejection of \(H_0\) if \(x_{(1)\geq c}\):
	\begin{align*}
		\alpha = 
		P[x_1\geq c|\eta_0] &= 
		e^{-n(c-\eta_0)} 
		\intertext{then,}
		\ln(\alpha) &= -n(c-\eta_0) 
		\intertext{next,}
		\frac{-\ln(\alpha)}{n} &= c-\eta_0 
		\intertext{finally,}
		\frac{-\ln(\alpha)}{n}+\eta_0 &= c.
	\end{align*}
\end{solution}
%\end{ Question 1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\begin{ Question 2}	  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\question 
Let \(X_1,\dots,X_n\) be a random sample from an exponential distribution, 
\(X\sim\operatorname{EXP}(\theta)\). 
Find a one-sided lower 95\% confidence limit for
\(P(X>t)=e^{-t/\theta}\) where \(t\) is an arbitrary known value.

%
%  Missing info is in problem 9 or 4?
% 

\begin{solution}
	\(\theta\) drawn from Problem 4.
\end{solution}
%\end{ Question 2}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\begin{ Question 3}	  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\question 
Let \(X\sim\operatorname{BIN}(n,p)\) and \(\hat{p}=X/n\).
Find a constant \(c\) so that
\(E\left[c\hat{p}(1-\hat{p})\right]=p(1-p)\).
\begin{solution}
	\begin{align*}
		p(1-p) &= E[c\hat{p}(1-\hat{p})] \\
		&= cE[\hat{p}]-cE[\hat{p}^2] \\
		\frac{p(1-p)}{c} &= E[\hat{p}]-E[\hat{p}^2] \\
		&= p(1-p)+\frac{p^2}{n} \\
		&= \frac{np(1-p)+p^2}{n} \\
		&= \frac{np-np^2+p^2}{n} \\
		&= \frac{p(n-np+p)}{n} \\
		\frac{(1-p)}{c} &= \frac{(1-p)(n-1)}{n} \\
		\frac{1}{c} &= \frac{n-1}{n} \\
		c &= \frac{n}{n-1}
	\end{align*}
\end{solution}
%\end{ Question 3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\begin{ Question 4}	  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\question 
Let \(X_1,\ldots,X_n\) be a random sample from an exponential distribution,
\(X\sim\operatorname{EXP}(\theta)\). 
If \(\bar{x}=17.9\) with \(n=50\), then find a one-sided lower 95\%
confidence limit for \(\theta\).
\begin{solution}
	% cite example 11.2.1 Engelhardt, Bain pg 361
	\begin{align*}
		\mathcalligra u(x)
		&= \frac{2n\bar{x}}{\chi^2_{1-\alpha}(2n)} \\
		&= \frac{2\cdot50(17.9)}{\chi^2_{0.05}(2\cdot50)} \\
		&= \frac{1790}{124.34} \\
		% Bain and Engelhard 124.34 for gamma =.9, 77.93 for 0.05
		% Chi-square table.com	124.342 
		% Scribbr.com		113.145
		&= 14.3960.
	\end{align*}
\end{solution}
%\end{ Question 4}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\begin{ Question 5}	  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\question 
Consider a random sample of size \(n\) from a Binomial distribution,
\(X_i\sim\operatorname{BIN}(1,p)\). 
Find the CRLB for the variances of unbiased estimators of \(p\).
\begin{solution}
	\begin{align*}
		\ln f(x) &= \ln\binom{n}{x}p^y(1-p)^{n-x} \\
		\intertext{using Sterling approximation}
			&= y \ln(p) + (n-x)ln(1-p) \\
	\intertext{First partial,}
		\frac{\partial}{\partial(p)}\ln f(x) &= \frac{x}{p} -\frac{(1-x)}{(1-p)} \\
	\intertext{then the second partial}
		\frac{\partial^2}{\partial(p)^2}\ln f(x)
			&= \frac{-x}{p^2} -\frac{(1-x)}{(1-p)^2} \\
	\intertext{Expected value}
		E\left[\frac{\partial^2}{\partial(p)^2}\ln f(x)\right]
		&= \frac{-p}{p^2} -\frac{(1-p)}{(1-p)^2}
		= \frac{-1}{p} -\frac{n}{(1-p)} 
		= \frac{-1}{p(1-p)} \\
	\intertext{insert into CRLB}
		\frac{1}{nE\left[\frac{\partial^2}{\partial(p)^2}\ln f(x)\right]}
		&= \frac{1}{-n\left(\frac{-1}{p(1-p)}\right)}
		= \frac{p(1-p)}{n}
	\end{align*}
\end{solution}
%\end{ Question 5}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\begin{ Question 6}	  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\question 
Consider a random sample of size from a uniform distribution,
\(X_i\sim\operatorname{UNIF}(0,\theta)\), \(\theta>0\),
and let \(X_{(n)}\) be the largest order statistic. 
Find constant \(c\) such that \((x_{(n)},cx_{(n)})\) is a \(100(1-\alpha)\%\) 
confidence interval for \(\theta\).
\begin{solution}
	\begin{align*}
		(1-\alpha) &= P(x_{(n)}<\theta<cx_{(n)}) \\
		&= P(\theta<cx_{(n)}) \\
		&= P(\frac{\theta}{c}<x_{(n)}) \\
		&= 1-P(x<\frac{\theta}{c})^n \\
		&= 1-(\frac{\theta}{\theta c})^n \\
		\alpha	&= (\frac{\theta}{\theta c})^n \\
		\alpha	&= (\frac{1}{c})^n \\
		\alpha^{\frac{1}{n}}	&= \frac{1}{c} \\
		\alpha^{\frac{-1}{n}}	&= c \\
	\end{align*}
	%
	% Ike also struggling on this one
	% https://math.stackexchange.com/questions/190436/confidence-interval-for-uniform
	% http://math.furman.edu/~dcs/courses/math47/lectures/lecture-16.pdf
	%
\end{solution}
%\end{ Question 6}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\begin{ Question 7}	  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\question 
Suppose that 45 workers in a textile mill are selected at random in a study of accident rate. 
The number of accidents per worker is assumed to be Poisson distributed with mean \(\mu\). 
The average number of accidents per worker is \(\bar{x}=1.7\).
Find an approximate one-sided lower 90\% confidence limit for \(\mu\) 
using eq (11.3.20).
\begin{solution}
	Eq. (11.3.20) = \(\frac{\bar{X}-\mu}{\sqrt{\mu/n}}\overset{d}{\rightarrow} Z\sim N(0,1)\); 
	which by theorem 7.7.4 is 
	\(\frac{\bar{X}-\mu}{\sqrt{\bar{X}/n}}\overset{d}{\rightarrow} Z\sim N(0,1)\).
	
	90\% CI $\rightarrow Z = 1.285$ 
	
	\begin{align*}
		\frac{1.7-\mu}{\sqrt{\mu/45}} &\rightarrow 1.285 \\
		\mu &< 1.7-1.285(\sqrt{1.7/45}) \\
		&< 1.7-1.285(\sqrt{0.194}) \\
		&< 1.7-1.285(0.24975) \\
		&< 1.45024
	\end{align*}
\end{solution}
%\end{ Question 7}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\begin{ Question 8}	  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\question 
Consider the biased coin discussed in Example 9.2.5, where the probability of a head, 
\(p\), is known to be 0.2, 0.30, or 0.80. 
The coin is tossed repeatedly, 
and we let \(X\) be the number of tosses required to obtain the first head. 
For a test of \(H_0\ :\,p=0.30\), suppose we use a rejection region of the form
\(\{1,14,15,\ldots\}\). Find \(P\left[\text{TI}\right]=\alpha=\)
% T[I] = Type 1 error.
\begin{solution}
	Constructing a table similar to Example 9.2.5: \\
	\begin{center}
		\begin{tabular}{c|rrr}
			& \multicolumn{3}{c}{\(p\)} \\ \toprule
			\(n\) & 0.2000 & 0.3000 &  0.8000 \\ \midrule
			1   & 0.2000 & 0.3000 &  0.8000 \\
			2   & 0.1600 & 0.2100 &  0.1600 \\
			3   & 0.1280 & 0.1470 &  0.0320 \\
			4   & 0.1024 & 0.1029 &  0.0064 \\
			5   & 0.0819 & 0.0720 &  0.0013 \\
			6   & 0.0655 & 0.0504 &  0.0003 \\
			7   & 0.0524 & 0.0353 &  0.0001 \\
			8   & 0.0419 & 0.0247 &  0.0000 \\
			9   & 0.0336 & 0.0173 &  0.0000 \\
			10   & 0.0268 & 0.0121 &  0.0000 \\
			11   & 0.0215 & 0.0085 &  0.0000 \\
			12   & 0.0172 & 0.0059 &  0.0000 \\
			13   & 0.0137 & 0.0042 &  0.0000 \\
			14   & 0.0110 & 0.0029 &  0.0000 \\
			15   & 0.0088 & 0.0020 &  0.0000 \\
			16   & 0.0070 & 0.0014 &  0.0000 \\ \bottomrule
			\end{tabular}
	\end{center}

	\begin{align*}
		P\left[\text{TI}\right]=\alpha&=1-\sum_{n\in[RR]}^{}(p)(1-p)^{1-n} \\
		&=1-\sum_{n=2}^{13}(0.3)(0.7)^{1-n} \\
		\intertext{using a spreadsheet to calculate, because doing so by hand would be tedious,}
		&= 0.3097.
	\end{align*}
\end{solution}
%\end{ Question 8}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%	\begin{ Question 9}	  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\question 
Let \(X_1,\ldots,X_n\) be a random sample from \(\operatorname{EXP}(\theta)\) where \(\hat{\theta_1}=\bar{X}\) and \(\hat{\theta_2}=\frac{n\bar{X}}{(n+1)}\). 
Compare the MSEs of \(\hat{\theta}_1\) and \(\hat{\theta}_2\) for \(n=2\).
\begin{solution}
	\begin{align*}
		\hat{\theta_1} &= \bar{X} \\
		\hat{\theta_2} & = \frac{n\bar{X}}{(n+1)} 
		= \frac{2}{3}\bar{X} \quad \text{for } n=2 \\
		\Rightarrow \bar{X} &> \frac{2}{3}\bar{X} \\
		\intertext{thus,}
		\text{MSE}[\hat{\theta}_1] &> \text{MSE}[\hat{\theta}_2]
	\end{align*}
\end{solution}
%\end{ Question 9}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  \begin{ Question 10}	  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\question 
Consider the biased coin discussed in Example 9.2.5, where the probability of a
head, \(p\), is known to be 0.2, 0.30, or 0.80. 
The coin is tossed repeatedly, and we let \(X\) be the number of tosses 
required to obtain the first head. For a test of \(H_0\ :\,p=0.30\), 
suppose we use a rejection region of the form \(\{1,14,15,\ldots\}\). 
Find \(P\left[\text{TII}\right]\) for \(p=0.2\).
%  P[TII] = Probability Type 2 error
\begin{solution}
	Re-using table from Problem 8 on this assignment:
	
	\begin{align*}
		P\left[\text{TII}\right]=\beta&=\sum_{n\in[RR]}^{}(p)(1-p)^{1-n} \\
		&=\sum_{n=2}^{13}(0.2)(0.8)^{1-n} \\
		\intertext{using a spreadsheet to calculate, because doing so by hand would be tedious,}
		&= 0.7450.
	\end{align*}
\end{solution}
%\end{ Question 10}

\end{questions}
\end{document}