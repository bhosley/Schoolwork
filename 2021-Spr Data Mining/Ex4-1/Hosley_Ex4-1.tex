\documentclass[]{article}
\usepackage{graphicx}
\usepackage{caption}
\graphicspath{ {./images/} }

% Minted
\usepackage[cache=false]{minted}
	\usemintedstyle{vs}
	\usepackage{xcolor}
		\definecolor{light-gray}{gray}{0.97}

\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{comment}

\title{Data Mining: Exercise 4-1}
\author{Brandon Hosley}
\date{\today}

\begin{document}
\maketitle

\section*{Assignment 1: First Method Classification}

\subsection*{Preparing Data}
\begin{minted}[breaklines,bgcolor=light-gray,fontsize=\footnotesize]{shell-session}
data = spark.read.format("libsvm").load("/user/data/CSC533DM/sample_libsvm_data.txt")
from pyspark.ml.feature import StringIndexer
labelIndexer = StringIndexer(inputCol="label",outputCol="indexedLabel").fit(data)
labelIndexer.transform(data).show(5)

from pyspark.ml.feature import VectorIndexer
featureIndexer = VectorIndexer(inputCol="features", outputCol="indexedFeatures",maxCategories=4).fit(data)
featureIndexer.transform(data).show(5)

(trainingData, testData) = data.randomSplit([0.7, 0.3])

trainingData.show(5)
testData.show(5)
\end{minted}
\includegraphics[width=\linewidth]{image1.1}
\includegraphics[width=\linewidth]{image1.2}
\includegraphics[width=\linewidth]{image1.3}
\includegraphics[width=\linewidth]{image1.4}

\subsection*{Training/Testing}
\begin{minted}[breaklines,bgcolor=light-gray,fontsize=\footnotesize]{shell-session}
from pyspark.ml.classification import DecisionTreeClassifier
dt = DecisionTreeClassifier(labelCol="indexedLabel",featuresCol="indexedFeatures")
from pyspark.ml import Pipeline
pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])
model = pipeline.fit(trainingData)
predictions = model.transform(testData)
#predictions.show(5)
predictions.select("prediction", "indexedLabel", "features").show(5)
\end{minted}
\includegraphics[width=\linewidth]{image2}

\subsection*{Evaluating Your Model}
\begin{minted}[breaklines,bgcolor=light-gray,fontsize=\footnotesize]{shell-session}
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
evaluator = MulticlassClassificationEvaluator(labelCol="indexedLabel",predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)
evaluator.setMetricName("weightedPrecision")
precision = evaluator.evaluate(predictions)
evaluator.setMetricName("weightedRecall")
Recall = evaluator.evaluate(predictions)
evaluator.setMetricName("f1")
f1Measure = evaluator.evaluate(predictions)

print("Accuracy: %g " % accuracy)
print("Precision: %g " % precision)
print("Recall: %g " % recall)
print("F1: %g " % f1Measure)
\end{minted}
\includegraphics[width=\linewidth]{image3}

\subsection*{Explain the Above Metric}
\emph{What they are. Explain based on your results/outputs, e.g. how they are calculated
Why some of their names are different and explain the difference, e.g. precision vs. weighted precision} \vspace{2em}

The definitions for the methods are provided by Spark documentation:
\begin{align*}
	ACC &= \frac{TP}{TP+FP} = \frac{1}{N}\sum_{i=0}^{N-1} \hat{\delta}(\hat{y}_i - y_i) \\
	
	PPV_w &= \frac{1}{N} \sum_{\ell \in L} \cdot \frac{
		\sum_{i=0}^{N-1} \hat{\delta} (\hat{y_i}-\ell) \cdot \hat{\delta} (y_i-\ell)
	}{\sum_{i=0}^{N-1} \hat{\delta} (\hat{y_i}-\ell)} 
	\cdot \sum_{i=0}^{N-1} \hat{\delta} (y_i -\ell) \\
	
	TPR_w &= \frac{1}{N} \sum_{\ell \in L} \cdot \sum_{i=0}^{N-1} \hat{\delta} (\hat{y_i}-\ell) \cdot \hat{\delta} (y_i-\ell)\\
	
	F_w(\beta) &= \\
\end{align*}

In Other words:\\
Accuracy is the ratio of true positives to true and false positives reported. \\
Precision is the same. \\
Recall is the ratio of true positives to all known positives. \\
When weighted these measurements are reported proportionately to the frequency of their corresponding labels. \\
The F-score is the harmonic mean of precision and recall. Which is the number of labels multiplied by the precisions and recalls of the label and divided by the sum of the precision and recalls. \\

\section*{Assignment 2: Second Method Classification}

\subsection*{Evaluate using Dataframe and RDD-Method}
To use RDD-based metrics, convert predictions (DataFrame) into predictionAndLabel (RDD), see References [7]

Use below metrics, see References [6]
	Accuracy
	Precision, Recall, F-1 measure (by label)
	Precision, Recall, F-1 measure (weighted)

\subsection*{Explain the differences of label and weighted based on your results.}


\end{document}


\begin{minted}[breaklines,bgcolor=light-gray,fontsize=\footnotesize]{shell-session}
\end{minted}
\includegraphics[width=\linewidth]{image1}