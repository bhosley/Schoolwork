\documentclass[]{article}
\usepackage{graphicx}
\usepackage{caption}
\graphicspath{ {./images/} }

% Minted
\usepackage[cache=false]{minted}
	\usemintedstyle{vs}
	\usepackage{xcolor}
		\definecolor{light-gray}{gray}{0.97}

\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{comment}

\title{Data Mining: Exercise 4-1}
\author{Brandon Hosley}
\date{\today}

\begin{document}
\maketitle

\section*{Assignment 1: First Method Classification}

\subsection*{Preparing Data}
\begin{minted}[breaklines,bgcolor=light-gray,fontsize=\footnotesize]{shell-session}
data = spark.read.format("libsvm").load("/user/data/CSC533DM/sample_libsvm_data.txt")
from pyspark.ml.feature import StringIndexer
labelIndexer = StringIndexer(inputCol="label",outputCol="indexedLabel").fit(data)
labelIndexer.transform(data).show(5)

from pyspark.ml.feature import VectorIndexer
featureIndexer = VectorIndexer(inputCol="features", outputCol="indexedFeatures",maxCategories=4).fit(data)
featureIndexer.transform(data).show(5)

(trainingData, testData) = data.randomSplit([0.7, 0.3])

trainingData.show(5)
testData.show(5)
\end{minted}
\includegraphics[width=\linewidth]{image1.1}
\includegraphics[width=\linewidth]{image1.2}
\includegraphics[width=\linewidth]{image1.3}
\includegraphics[width=\linewidth]{image1.4}

\subsection*{Training/Testing}
\begin{minted}[breaklines,bgcolor=light-gray,fontsize=\footnotesize]{shell-session}
from pyspark.ml.classification import DecisionTreeClassifier
dt = DecisionTreeClassifier(labelCol="indexedLabel",featuresCol="indexedFeatures")
from pyspark.ml import Pipeline
pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])
model = pipeline.fit(trainingData)
predictions = model.transform(testData)
#predictions.show(5)
predictions.select("prediction", "indexedLabel", "features").show(5)
\end{minted}
\includegraphics[width=\linewidth]{image2}

\subsection*{Evaluating Your Model}
\begin{minted}[breaklines,bgcolor=light-gray,fontsize=\footnotesize]{shell-session}
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
evaluator = MulticlassClassificationEvaluator(labelCol="indexedLabel",predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)
evaluator.setMetricName("weightedPrecision")
precision = evaluator.evaluate(predictions)
evaluator.setMetricName("weightedRecall")
Recall = evaluator.evaluate(predictions)
evaluator.setMetricName("f1")
f1Measure = evaluator.evaluate(predictions)

print("Accuracy: %g " % accuracy)
print("Precision: %g " % precision)
print("Recall: %g " % recall)
print("F1: %g " % f1Measure)
\end{minted}
\includegraphics[width=\linewidth]{image3}

\subsection*{Explain the Above Metric}
\emph{What they are. Explain based on your results/outputs, e.g. how they are calculated
Why some of their names are different and explain the difference, e.g. precision vs. weighted precision} \vspace{2em}

The definitions for the methods are provided by Spark documentation:
\begin{align*}
	ACC &= \frac{TP}{TP+FP} = \frac{1}{N}\sum_{i=0}^{N-1} \hat{\delta}(\hat{y}_i - y_i) \\	
	PPV_w &= \frac{1}{N} \sum_{\ell \in L} \frac{
		\sum_{i=0}^{N-1} \hat{\delta} (\hat{y_i}-\ell) \cdot \hat{\delta} (y_i-\ell)
	}{\sum_{i=0}^{N-1} \hat{\delta} (\hat{y_i}-\ell)} 
	\cdot \sum_{i=0}^{N-1} \hat{\delta} (y_i -\ell) \\	
	TPR_w &= \frac{1}{N} \sum_{\ell \in L} \sum_{i=0}^{N-1} \hat{\delta} (\hat{y_i}-\ell) \cdot \hat{\delta} (y_i-\ell)\\
	F_w(\beta) &=
		\frac{1}{N}
		\sum_{\ell \in L} (1+\beta^2) \cdot
		(\frac{PPV(\ell) \cdot TPR(\ell)}{\beta^2 \cdot PPV(\ell)+TPR(\ell)}) \cdot
		\sum_{i=0}^{N-1} \hat{\delta} (y_i -\ell) \\
\end{align*}

In Other words:\\
Accuracy is the ratio of true positives to true and false positives reported. \\
Precision is the same. \\
Recall is the ratio of true positives to all known positives. \\
When weighted these measurements are reported proportionately to the frequency of their corresponding labels. \\
The F-score is the harmonic mean of precision and recall. Which is the number of labels multiplied by the precisions and recalls of the label and divided by the sum of the precision and recalls. \\

\section*{Assignment 2: Second Method Classification}

\subsection*{Evaluate using Dataframe and RDD-Method}
\emph{
To use RDD-based metrics, convert predictions (DataFrame) into predictionAndLabel (RDD), see References [7]}

\emph{
Use below metrics, see References [6] \\
	Accuracy \\
	Precision, Recall, F-1 measure (by label) \\
	Precision, Recall, F-1 measure (weighted)} \\ 
	
\begin{minted}[breaklines,bgcolor=light-gray,fontsize=\footnotesize]{shell-session}
from pyspark.mllib.evaluation import MulticlassMetrics
predictionAndLabels = predictions.select("prediction", "indexedLabel").rdd
metrics = MulticlassMetrics(predictionAndLabels)

# Statistics by class
#labels = predictionAndLabels.map(lambda lp: lp.label).distinct().collect()
labels = [0.0,1.0]
for label in sorted(labels):
print("Class %s precision = %s" % (label, metrics.precision(label)))
print("Class %s recall = %s" % (label, metrics.recall(label)))
print("Class %s F1 Measure = %s" % (label, metrics.fMeasure(label, beta=1.0)))

# Weighted stats
print("Weighted recall = %s" % metrics.weightedRecall)
print("Weighted precision = %s" % metrics.weightedPrecision)
print("Weighted F(1) Score = %s" % metrics.weightedFMeasure())
print("Weighted F(0.5) Score = %s" % metrics.weightedFMeasure(beta=0.5))
print("Weighted false positive rate = %s" % metrics.weightedFalsePositiveRate)
\end{minted}
\includegraphics[width=\linewidth]{image4.1}
\includegraphics[width=\linewidth]{image4.2}

\subsection*{Explain the differences of label and weighted based on your results.}

As above, the labeled measurements are based on their corresponding label. The weighted results are the values in proportion to the frequency of their true label in the dataset.

\textbf{Note:} The fact that all three measures are reported as identical is uncommon but indicates that false positives and false negatives are equal. Checking the confusion matrix verifies that this is the case and may not indicate an error in the script.

\includegraphics[width=\linewidth]{image6}

\end{document}


\begin{minted}[breaklines,bgcolor=light-gray,fontsize=\footnotesize]{shell-session}
\end{minted}
\includegraphics[width=\linewidth]{image1}