\documentclass[12pt,letterpaper]{exam}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{alphabeta}
\usepackage[width=8.50in, height=11.00in, left=0.50in, right=0.50in, top=0.50in, bottom=0.50in]{geometry}

\usepackage{libertine}
\usepackage{multicol}
\usepackage[shortlabels]{enumitem}

\usepackage{booktabs}
\usepackage[table]{xcolor}

\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{bbm}

\usepackage{hyperref}
\usepackage{graphicx}
%\usepackage{wrapfig}
%\usepackage{capt-of}
%\usepackage{tikz}
%\usepackage{pgfplots}
%\usetikzlibrary{shapes,arrows,positioning,patterns}
%\usepackage{pythonhighlight}

\newcommand\chapter{8}
\renewcommand{\thequestion}{\textbf{\chapter.\arabic{question}}}
\renewcommand{\questionlabel}{\thequestion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\class}{  } % This is the name of the course 
\newcommand{\assignmentname}{Homework \# \chapter} % 
\newcommand{\authorname}{Hosley, Brandon} % 
\newcommand{\workdate}{\today} % 
\printanswers % this includes the solutions sections
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\pagestyle{plain}
\thispagestyle{empty}
\noindent

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent
\begin{tabular*}{\textwidth}{l @{\extracolsep{\fill}} r @{\extracolsep{10pt}} l}
	\textbf{\class} & \textbf{\authorname}  &\\ %Your name here instead, obviously
	\textbf{\assignmentname } & \textbf{\workdate} & \\
\end{tabular*}\\
\rule{\textwidth}{2pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% HEADER %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{questions}

	\question 
	In 1,000 tosses of a coin, 560 heads and 440 tails appear. 
	Is it reasonable to assume that the coin is fair? Justify your answer.
	
	\begin{solution}
		If the coin is 'fair' we typically assume that the \(p=1-p\) and therefore \(p=0.5\).
		Further, we expect \(X\sim \text{bin}(1000,0.5)\), and
		
		\( E[X] = np = 500 \),
		
		\( Var[X] = np(1-p) = 250\).
		
		Then, noting that as \(n\rightarrow\infty\) the binomial approaches normal distribution.
		We can utilize the normal distribution to approximate the probability of this coin's result.
		\begin{align*}
			z &= \frac{x-\mu}{\sigma} \\
			&= \frac{60}{\sqrt{250}} \\
			&= 3.7947,
		\intertext{thus,}
			P(Z\geq z)  &= P(Z\geq 3.7947) .\\
		\end{align*}
		With this value we can calculate an approximate probability;
		of the first 4 tables that I consulted, the highest \(Z\) score was \(3.69\)
		which returns a value of \(0.0001\).
		Thus, even without an exact answer we can determine that it is highly unlikely that this
		particular coin is fair (\(p=0.5\)).
	\end{solution}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\setcounter{question}{3-1}
	
	\question 
	Here, the LRT alluded to in Example 8.2.9 will be derived. 
	Suppose that we observe \(m\) iid Bernoulli(\(\theta\)) random variables, denoted \(Y_1,...,Y_m\). 
	Show that the LRT of \(H_0: \theta \leq \theta_0\) versus \(H_1:\theta > \theta_0\) will reject \(H_0\) if \(\sum_{i=1}^{m} Y_i > b\).
	
	\begin{solution}
		H
	\end{solution}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\setcounter{question}{12-1}
	
	\question 
	For sample size \(n = 1, 4, 16, 64, 100\) from a normal population with mean \(\mu\) and known variance \(\sigma^2\), 
	plot the power function following the LRTs. Take \(\alpha = 0.05\)
	\begin{parts}
		\part \(H_0: \mu \le 0\) versus \(H_1:\mu > 0\)
		\part \(H_0: \mu = 0\) versus \(H_1:\mu \ne 0\)
	\end{parts}
	
	\begin{solution}
		Borrowing the normal power function from Casella and Berger example 8.3.3
		\begin{align*}
			\beta(\theta)
			&= P\left(Z>c+\frac{\theta_0-\theta}{\sigma/\sqrt{n}}\right) \\
			&= P\left(\frac{\bar{X}-\theta}{\sigma/\sqrt{n}}>1.645+\frac{\theta_0-\theta}{\sigma}\sqrt{n}\right)
		\end{align*}
	\end{solution}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	%\setcounter{question}{14-1}
	%\question For a random sample $X_1, ..., X_n$ of Bernoulli($p$) variables, it is desired to test $$H_0: p = .49 \quad\text{versus}\quad H_1: p = .51$$
	%Use the Central Limit Theorem ot determine, approximately, the sample size needed so that the two probability of error are both about .01. Use a test function that rejects $H_0$ if $\sum_{i=1}^{n} X_i$ is large.
	%\begin{solution}
	%	Here is the next solution
	%\end{solution}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\setcounter{question}{15-1}
	
	\question 
	Show that for a random sample $X_1, ..., X_n$ from a $N(0,\sigma^2)$ population, 
	the most powerful test of $H_0: \sigma = \sigma_0$ versus $H_1: \sigma = \sigma_1$, 
	where $\sigma_0 < \sigma_1$, is given by
	\begin{align*}
		\phi\left(\Sigma X_i^2\right) =
		\begin{cases}
			1 &, \Sigma X_i^2 > c \\
			0 &, \Sigma X_i^2 \le c.
		\end{cases}
	\end{align*}
	For a given value of $\alpha$, the size of the Type I Error, show how the value of $c$ is explicitly determined.
	
	\begin{solution}
		Here is the next solution
	\end{solution}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\setcounter{question}{19-1}
	
	\question 
	The random variable $X$ has pdf $f(x) = e^{-x}, x> 0$. 
	One observation is obtained on the random variable $Y = X^\theta$, 
	and a test of $H_0: \theta = 1$ versus $H_1: \theta = 2$ needs to be constructed. 
	Find the UMP level $\alpha = .10$ test and compute the Type II Error probability.

	\begin{solution}
		Here is the next solution
	\end{solution}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\setcounter{question}{20-1}
	
	\question 
	Let $X$ be a random variable whose pmf under $H_0$ and $H_1$ is given by
	$$
	\begin{array}{cccccccc}
		x & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\ \hline
		f(x|H_0) & .01 & .01 & .01 & .01 & .01 & .01 & .94 \\
		f(x|H_1) & .06 & .05 & .04 & .03 & .02 & .01 & .79 \\
	\end{array}
	$$
	Use the Neyman-Pearson Lemma to find the most powerful test for $H_0$ versus $H_1$ with size $\alpha = .04$. 
	Compute the probability of Type II Error for this test.

	\begin{solution}
		Here is the next solution
	\end{solution}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\setcounter{question}{23-1}
	
	\question 
	Suppose $X$ is one observation from a population with beta($\theta$, 1) pdf.
	\begin{parts}
		\part For testing $H_0: \theta \le 1$ versus $H_1: \theta > 1$, 
			find the size and sketch the power function of the test that rejects $H_0$ if $X > \frac{1}{2}$.
		\part Find the most powerful level $\alpha$ test fo $H_0: \theta =1$ versus $H_1: \theta = 2$.
		\part Is there a UMP test of $H_0: \theta \le 1$ versus $H_1: \theta > 1$? If so, find it. If not, prove so.
	\end{parts}
	
	\begin{solution}
		Here is the next solution
	\end{solution}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\setcounter{question}{28-1}
	
	\question 
	Let $f(x|\theta)$ be the logistic location pdf
	$$
	f(x|\theta)
	= \frac{ e^{(x-\theta)} }{ (1 + e^{(x-\theta)})^2 }, \quad -\infty < x < \infty, \quad -\infty < \theta < \infty
	$$
	\begin{parts}
		\part Show that this familiy has an MLR.
		\part Based on one observation, $X$, find the most powerful size $\alpha$ test of $H_0: \theta = 0$ versus $H_1: \theta =1$. 
			For $\alpha$ = .2, find the size of the Type II Error.
		\part  Show that the test in part (b) is UMP size $\alpha$ for testing $H_0: \theta \le 0$ versus $H_1: \theta > 0$. What can be said about UMP tests in general for the logistic location family?
	\end{parts}
	
	\begin{solution}
		Here is the next solution
	\end{solution}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\setcounter{question}{37-1}
	
	\question 
	Let $X_1, ..., X_n$ be a random sample from a n($\theta, \sigma^2$) population. 
	Consider testing $$H_0: \theta \le \theta_0 \quad \text{versus} \quad H_1: \theta > \theta_0.$$
	\begin{parts}
		\part If $\sigma^2$ is known, show that the test that rejects $H_0$ when
		$$\bar{X} > \theta_0 + z_\alpha \sqrt{\sigma^2/n}$$
		is a test of size $\alpha$. Show that the test can be derived as an LRT.
		\part Show that the test in part (a) is a UMP test
		\part If $\sigma^2$ is unknown, show that the test that rejects $H_0$ when
		$$\bar{X} > \theta_0 + z_{n-1,\alpha} \sqrt{S^2/n}$$ is a test of size $\alpha$. Show that the test can be derived as an LRT.
	\end{parts}
	
	\begin{solution}
		Here is the next solution
	\end{solution}

\end{questions}
\end{document}
