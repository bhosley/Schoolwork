\documentclass{beamer}
\usetheme{Darmstadt}
\usecolortheme{beaver}
\usepackage{booktabs}
\usepackage{hyperref}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {./images/} }

%Information to be included in the title page:
\title{Advanced Statistical Methods \\ Homework 8}
\author{Brandon Hosley}
\institute{University of Illinois - Springfield}
\date{\today}

\begin{document}
\frame{\titlepage}

\begin{frame}{Overview}
\tableofcontents
\end{frame}

\section[SVM]{Support Vector Machines}

\begin{frame}{Support Vector Machines}
	\begin{itemize}
		\item (Usually) Supervised Learning Method
		\item Calculates an N-1 dimensional hyperplane to be used as a linear classifier
		\item The hyperplane is calculated such that it has the largest possible margin from available data
	\end{itemize}
	\vspace{0.25em}
	\centering
	\includegraphics[width=0.35\linewidth]{SVM.png}
\end{frame}

\section[PCA]{Principal Component Analysis}

\begin{frame}{Principal Component Analysis}
	\begin{itemize}
		\item Exploratory Data Analysis
		\item Aims to discover 'Principal' components 
		\item[] Components with the highest capacity for prediction
	\end{itemize}
	\centering
	\includegraphics[width=0.5\linewidth]{GaussianScatterPCA.png}
\end{frame}

\begin{frame}{Principal Component Analysis}
	How is capacity for prediction determined?
	\begin{itemize}
		\item Two Orthogonal vectors are fit to the data
		\item[] (Similar to axes of an ellipse wrapped around the data
		\item The Two axes are orthonormalized
		\item This will form the basis on which a covariance matrix will be plotted
	\end{itemize}
	\centering
	\includegraphics[width=0.35\linewidth]{PCA.jpg}
\end{frame}

\begin{frame}{Principal Component Analysis}
	How is capacity for prediction determined?
	\begin{itemize}
		\item The Covariance matrix is transformed with the earlier determined basis
		\item The resulting slope is the variance of that component
		\item Each variance can be divided by the sum variance to provide a proportion
		\item Principal components are those that make up the lowest proportions of variance
	\end{itemize}
	\centering
	\includegraphics[width=0.35\linewidth]{Covariance.png}
\end{frame}

\section[K-Means]{K-Mean Clustering}

\begin{frame}{K-Means Clustering}
	\begin{itemize}
		\item A (comparatively) simple method of classification
		\item[] With relatively good results
		\item The mean of each cluster is calculated and new data is classified to the nearest mean
		\item Divisions can be drawn as Voronoi cells
	\end{itemize}
	\vspace{0.25em}
	\begin{columns}
		\column[]{0.5\linewidth}
		\centering
		\includegraphics[width=0.8\linewidth]{clusters.jpg}
		\column[]{0.5\linewidth}
		\centering
		\includegraphics[width=0.6\linewidth]{Voronoi.png}
	\end{columns}	
\end{frame}

\end{document}
